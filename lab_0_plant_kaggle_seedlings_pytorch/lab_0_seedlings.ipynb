{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tel-Aviv Deep Learning Boot-camp: 12 Applied Deep Learning Labs\n",
    "\n",
    "## Lab 0: Plant Seedlings Classification (PyTorch): The most basic lab :)  \n",
    "\n",
    "<img src=\"../assets/seedlings.png\" align=\"center\">\n",
    "\n",
    "### Instructors:\n",
    "\n",
    "- Shlomo Kashani: shlomo@bayesian.io ,\n",
    "- Nathaniel Shimoni nathaniel.shimoni@grid4c.com \n",
    "\n",
    "<img src=\"../assets/pt.jpg\" width=\"35%\" align=\"center\">\n",
    "\n",
    "### Links:\n",
    "\n",
    "- https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/ \n",
    "- Git: https://github.com/bayesianio/applied-dl-2018\n",
    "- Full info: https://www.evernote.com/shard/s341/sh/3855640e-2b0b-42e5-b5b9-00216d02ac9a/b47968226e49a81ee813901cd41d3924\n",
    "\n",
    "### Date and Location: \n",
    "- July 2018\n",
    "\n",
    "\n",
    "### Requirements:\n",
    "- Python 3.5, CUDA 9, cuDNN 7, PyTorch 2.0 or above, Keras 2 or above\n",
    "\n",
    "#### For Windows 10 and Windows Server 2016, CUDA 9\n",
    "`conda install -c peterjc123 pytorch cuda90`\n",
    "\n",
    "\n",
    "### Data\n",
    "- Download: https://www.kaggle.com/c/plant-seedlings-classification\n",
    "\n",
    "- Please make sure you have already set up a Pytorch tree structure of your dataset:\n",
    "- `data_dir= '/home/data/bone/train/' `\n",
    "\n",
    "```\n",
    "    data_dir= '/home/data/bone/train/\n",
    "    \n",
    "    ├── valid\n",
    "    │   └── Type_1\n",
    "        ├── Type_2\n",
    "        └── Type_3\n",
    "    └── train\n",
    "        ├── Type_1\n",
    "        ├── Type_2\n",
    "        └── Type_3\n",
    "```\n",
    "\n",
    "### PyTorch Datasets\n",
    "\n",
    "To create a dataset, we subclass Dataset and define a constructor, a `__len__` method, and a `__getitem__` method. \n",
    "Here is full example:\n",
    "\n",
    "```python\n",
    "class BoneDataset(Dataset):\n",
    "    def __init__(self, labels, root_dir, subset=False, transform=None):\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels.iloc[idx, 0] # file name\n",
    "        fullname = join(self.root_dir, img_name)\n",
    "        image = Image.open(fullname).convert('RGB')\n",
    "        labels = self.labels.iloc[idx, 2] # category_id\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n",
    "```\n",
    "\n",
    "### The PyTorch DataLoader Class¶\n",
    "- Will load our BoneDataset\n",
    "- Can be regarded as a list (or iterator, technically).\n",
    "- Each time it is invoked will provide a minibatch of (img, label) pairs.\n",
    "\n",
    "\n",
    "### Training with TensorBoard\n",
    "\n",
    "With the aid of [Crayon](https://github.com/torrvision/crayon),\n",
    "we can access the visualisation power of TensorBoard for any \n",
    "deep learning framework.\n",
    "\n",
    "To use the TensorBoard, install Crayon (https://github.com/torrvision/crayon)\n",
    "and set `use_tensorboard = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "42dcf0c0-28f0-4386-9ee3-367f3606aa30",
    "_uuid": "33595673f3f93faf28ed0ac10f0a7c0e59a9c0ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.6.2 |Anaconda custom (64-bit)| (default, Sep 19 2017, 08:03:39) [MSC v.1900 64 bit (AMD64)]\n",
      "__pyTorch VERSION: 0.2.1+a4fc05a\n",
      "__CUDA VERSION\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2017 NVIDIA Corporation\n",
      "Built on Fri_Sep__1_21:08:32_Central_Daylight_Time_2017\n",
      "Cuda compilation tools, release 9.0, V9.0.176\n",
      "__CUDNN VERSION: None\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n",
      "Available devices  1\n",
      "Current cuda device  0\n",
      "USE CUDA=True\n"
     ]
    }
   ],
   "source": [
    "%reset -f \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from shutil import copyfile\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as func\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import random \n",
    "\n",
    "\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "# call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "print(\"USE CUDA=\" + str (use_cuda))\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "manualSeed = None\n",
    "def fixSeed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "if manualSeed is None:\n",
    "        manualSeed = 999\n",
    "fixSeed(manualSeed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "579bc4ea-49c2-4413-a4bf-57472a155db4",
    "_uuid": "ab87c9fc87053c27d96e4765be8a942e91bf79bd"
   },
   "source": [
    "### Define Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "796ac7f9-d66a-4856-acba-b1be8f4960b6",
    "_uuid": "e32251e2e44d9bf3b14af6153643b36110cb17ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black-grass/0050f38b3.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black-grass/0183fdf68.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black-grass/0260cffa8.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black-grass/05eedce4d.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black-grass/075d004bc.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file     category  category_id\n",
       "0  Black-grass/0050f38b3.png  Black-grass            0\n",
       "1  Black-grass/0183fdf68.png  Black-grass            0\n",
       "2  Black-grass/0260cffa8.png  Black-grass            0\n",
       "3  Black-grass/05eedce4d.png  Black-grass            0\n",
       "4  Black-grass/075d004bc.png  Black-grass            0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BoneDataset(Dataset):\n",
    "    def __init__(self, labels, root_dir, subset=False, transform=None):\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels.iloc[idx, 0] # file name\n",
    "        fullname = join(self.root_dir, img_name)\n",
    "        image = Image.open(fullname).convert('RGB')\n",
    "        labels = self.labels.iloc[idx, 2] # category_id\n",
    "#         print (labels)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n",
    "    \n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "data_dir= 'd:/db/data/bone/train/'\n",
    "data_dir= 'd:/db/data/cat-dog/train/'\n",
    "data_dir= 'd:/db/data/seedings/train/'\n",
    "\n",
    "def find_classes(fullDir):\n",
    "    classes = [d for d in os.listdir(fullDir) if os.path.isdir(os.path.join(fullDir, d))]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    num_to_class = dict(zip(range(len(classes)), classes))\n",
    "    \n",
    "    train = []\n",
    "    for index, label in enumerate(classes):\n",
    "        path = fullDir + label + '/'\n",
    "        for file in listdir(path):\n",
    "            train.append(['{}/{}'.format(label, file), label, index])\n",
    "    \n",
    "    df = pd.DataFrame(train, columns=['file', 'category', 'category_id',]) \n",
    "\n",
    "    return classes, class_to_idx, num_to_class, df\n",
    "\n",
    "classes, class_to_idx, num_to_class, df =find_classes (data_dir )\n",
    "\n",
    "\n",
    "# class_to_idx\n",
    "# num_to_class\n",
    "df.head(5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation \n",
    "- Many of the code snippts here were adapted from various github repos.\n",
    "- If you dont need augementation, just skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "from torchvision.transforms import *\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import numbers\n",
    "import math\n",
    "import torch\n",
    "import torch\n",
    "import random\n",
    "import PIL.ImageEnhance as ie\n",
    "import PIL.Image as im\n",
    "\n",
    "# adapted from https://github.com/kuangliu/pytorch-retinanet/blob/master/transform.py\n",
    "# https://github.com/mratsim/Amazon-Forest-Computer-Vision/blob/master/src/p_data_augmentation.py\n",
    "\n",
    "normalize_img = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def draw(img, boxes):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for box in boxes:\n",
    "        draw.rectangle(list(box), outline='red')\n",
    "    img.show()\n",
    "\n",
    "\n",
    "class Stack(object):\n",
    "\n",
    "    def __init__(self, roll=False):\n",
    "        self.roll = roll\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        if img_group[0].mode == 'L':\n",
    "            return np.concatenate([np.expand_dims(x, 2) for x in img_group], axis=2)\n",
    "        elif img_group[0].mode == 'RGB':\n",
    "            if self.roll:\n",
    "                return np.concatenate([np.array(x)[:, :, ::-1] for x in img_group], axis=2)\n",
    "            else:\n",
    "                return np.concatenate(img_group, axis=2)\n",
    "\n",
    "\n",
    "class ToTorchFormatTensor(object):\n",
    "    \"\"\" Converts a PIL.Image (RGB) or numpy.ndarray (H x W x C) in the range [0, 255]\n",
    "    to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \"\"\"\n",
    "    def __init__(self, div=True):\n",
    "        self.div = div\n",
    "\n",
    "    def __call__(self, pic):\n",
    "        if isinstance(pic, np.ndarray):\n",
    "            # handle numpy array\n",
    "            img = torch.from_numpy(pic).permute(2, 0, 1).contiguous()\n",
    "        else:\n",
    "            # handle PIL Image\n",
    "            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
    "            img = img.view(pic.size[1], pic.size[0], len(pic.mode))\n",
    "            # put it from HWC to CHW format\n",
    "            # yikes, this transpose takes 80% of the loading time/CPU\n",
    "            img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "        return img.float().div(255) if self.div else img.float()\n",
    "\n",
    "\n",
    "class IdentityTransform(object):\n",
    "\n",
    "    def __call__(self, data):\n",
    "        return data\n",
    "\n",
    "class RandomErasing(object):\n",
    "    def __init__(self, EPSILON = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n",
    "        self.EPSILON = EPSILON\n",
    "        self.mean = mean\n",
    "        self.sl = sl\n",
    "        self.sh = sh\n",
    "        self.r1 = r1\n",
    "       \n",
    "    def __call__(self, img):\n",
    "\n",
    "        if random.uniform(0, 1) > self.EPSILON:\n",
    "            return img\n",
    "\n",
    "        for attempt in range(100):\n",
    "            area = img.size()[1] * img.size()[2]\n",
    "       \n",
    "            target_area = random.uniform(self.sl, self.sh) * area\n",
    "            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n",
    "\n",
    "            h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "            w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "            if w <= img.size()[2] and h <= img.size()[1]:\n",
    "                x1 = random.randint(0, img.size()[1] - h)\n",
    "                y1 = random.randint(0, img.size()[2] - w)\n",
    "                if img.size()[0] == 3:\n",
    "                    #img[0, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
    "                    #img[1, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
    "                    #img[2, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
    "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
    "                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n",
    "                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n",
    "                    #img[:, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(3, h, w))\n",
    "                else:\n",
    "                    img[0, x1:x1+h, y1:y1+w] = self.mean[1]\n",
    "                    # img[0, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(1, h, w))\n",
    "                return img\n",
    "\n",
    "        return img\n",
    "\n",
    "def random_crop(img, boxes):\n",
    "    '''Crop the given PIL image to a random size and aspect ratio.\n",
    "    A crop of random size of (0.08 to 1.0) of the original size and a random\n",
    "    aspect ratio of 3/4 to 4/3 of the original aspect ratio is made.\n",
    "    Args:\n",
    "      img: (PIL.Image) image to be cropped.\n",
    "      boxes: (tensor) object boxes, sized [#ojb,4].\n",
    "    Returns:\n",
    "      img: (PIL.Image) randomly cropped image.\n",
    "      boxes: (tensor) randomly cropped boxes.\n",
    "    '''\n",
    "    success = False\n",
    "    for attempt in range(10):\n",
    "        area = img.size[0] * img.size[1]\n",
    "        target_area = random.uniform(0.56, 1.0) * area\n",
    "        aspect_ratio = random.uniform(3. / 4, 4. / 3)\n",
    "\n",
    "        w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "        h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            w, h = h, w\n",
    "\n",
    "        if w <= img.size[0] and h <= img.size[1]:\n",
    "            x = random.randint(0, img.size[0] - w)\n",
    "            y = random.randint(0, img.size[1] - h)\n",
    "            success = True\n",
    "            break\n",
    "\n",
    "    # Fallback\n",
    "    if not success:\n",
    "        w = h = min(img.size[0], img.size[1])\n",
    "        x = (img.size[0] - w) // 2\n",
    "        y = (img.size[1] - h) // 2\n",
    "\n",
    "    img = img.crop((x, y, x+w, y+h))\n",
    "    boxes -= torch.Tensor([x,y,x,y])\n",
    "    boxes[:,0::2].clamp_(min=0, max=w-1)\n",
    "    boxes[:,1::2].clamp_(min=0, max=h-1)\n",
    "    return img, boxes\n",
    "\n",
    "\n",
    "class Lighting(object):\n",
    "    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n",
    "\n",
    "    def __init__(self, alphastd, eigval, eigvec):\n",
    "        self.alphastd = alphastd\n",
    "        self.eigval = eigval\n",
    "        self.eigvec = eigvec\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.alphastd == 0:\n",
    "            return img\n",
    "\n",
    "        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n",
    "        rgb = self.eigvec.type_as(img).clone() \\\n",
    "            .mul(alpha.view(1, 3).expand(3, 3)) \\\n",
    "            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n",
    "            .sum(1).squeeze()\n",
    "\n",
    "        return img.add(rgb.view(3, 1, 1).expand_as(img))\n",
    "\n",
    "\n",
    "class Grayscale(object):\n",
    "    def __call__(self, img):\n",
    "        gs = img.clone()\n",
    "        gs[0].mul_(0.299).add_(0.587, gs[1]).add_(0.114, gs[2])\n",
    "        gs[1].copy_(gs[0])\n",
    "        gs[2].copy_(gs[0])\n",
    "        return gs\n",
    "\n",
    "\n",
    "class Saturation(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = Grayscale()(img)\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class Brightness(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = img.new().resize_as_(img).zero_()\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class Contrast(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = Grayscale()(img)\n",
    "        gs.fill_(gs.mean())\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class RandomOrder(object):\n",
    "    \"\"\" Composes several transforms together in random order.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.transforms is None:\n",
    "            return img\n",
    "        order = torch.randperm(len(self.transforms))\n",
    "        for i in order:\n",
    "            img = self.transforms[i](img)\n",
    "        return img\n",
    "\n",
    "\n",
    "class ColorJitter(RandomOrder):\n",
    "    def __init__(self, brightness=0.4, contrast=0.4, saturation=0.4):\n",
    "        self.transforms = []\n",
    "        if brightness != 0:\n",
    "            self.transforms.append(Brightness(brightness))\n",
    "        if contrast != 0:\n",
    "            self.transforms.append(Contrast(contrast))\n",
    "        if saturation != 0:\n",
    "            self.transforms.append(Saturation(saturation))\n",
    "\n",
    "\n",
    "class RandomFlip(object):\n",
    "    \"\"\"Randomly flips the given PIL.Image with a probability of 0.25 horizontal,\n",
    "                                                                0.25 vertical,\n",
    "                                                                0.5 as is\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, img):\n",
    "        dispatcher = {\n",
    "            0: img,\n",
    "            1: img,\n",
    "            2: img.transpose(im.FLIP_LEFT_RIGHT),\n",
    "            3: img.transpose(im.FLIP_TOP_BOTTOM)\n",
    "        }\n",
    "\n",
    "        return dispatcher[random.randint(0, 3)]  # randint is inclusive\n",
    "\n",
    "\n",
    "class RandomRotate(object):\n",
    "    \"\"\"Randomly rotate the given PIL.Image with a probability of 1/6 90°,\n",
    "                                                                 1/6 180°,\n",
    "                                                                 1/6 270°,\n",
    "                                                                 1/2 as is\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, img):\n",
    "        dispatcher = {\n",
    "            0: img,\n",
    "            1: img,\n",
    "            2: img,\n",
    "            3: img.transpose(im.ROTATE_90),\n",
    "            4: img.transpose(im.ROTATE_180),\n",
    "            5: img.transpose(im.ROTATE_270)\n",
    "        }\n",
    "\n",
    "        return dispatcher[random.randint(0, 5)]  # randint is inclusive\n",
    "\n",
    "\n",
    "class PILColorBalance(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Color(img).enhance(alpha)\n",
    "\n",
    "\n",
    "class PILContrast(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Contrast(img).enhance(alpha)\n",
    "\n",
    "\n",
    "class PILBrightness(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Brightness(img).enhance(alpha)\n",
    "\n",
    "\n",
    "class PILSharpness(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Sharpness(img).enhance(alpha)\n",
    "\n",
    "\n",
    "# Check ImageEnhancer effect: https://www.youtube.com/watch?v=_7iDTpTop04\n",
    "# Not documented but all enhancements can go beyond 1.0 to 2\n",
    "# Image must be RGB\n",
    "# Use Pillow-SIMD because Pillow is too slow\n",
    "class PowerPIL(RandomOrder):\n",
    "    def __init__(self, rotate=True,\n",
    "                 flip=True,\n",
    "                 colorbalance=0.4,\n",
    "                 contrast=0.4,\n",
    "                 brightness=0.4,\n",
    "                 sharpness=0.4):\n",
    "        self.transforms = []\n",
    "        if rotate:\n",
    "            self.transforms.append(RandomRotate())\n",
    "        if flip:\n",
    "            self.transforms.append(RandomFlip())\n",
    "        if brightness != 0:\n",
    "            self.transforms.append(PILBrightness(brightness))\n",
    "        if contrast != 0:\n",
    "            self.transforms.append(PILContrast(contrast))\n",
    "        if colorbalance != 0:\n",
    "            self.transforms.append(PILColorBalance(colorbalance))\n",
    "        if sharpness != 0:\n",
    "            self.transforms.append(PILSharpness(sharpness))\n",
    "\n",
    "def default_loader(input_path):\n",
    "    input_image = (Image.open(input_path)).convert('RGB')\n",
    "    return input_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bc8a9969-280a-4ec8-850b-25aed1ee38d6",
    "_uuid": "0163fcd2a2ea5a4e93bc87f47a96f404bcad6a83"
   },
   "source": [
    "## Setup transforms, datasets, and dataloaders\n",
    "\n",
    "- Data loaders spit out data from a dataset in batches. This is what you actually feed the neural network during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "f94cb9fa-e76a-46d5-a363-8856b45c59e1",
    "_uuid": "fe82da4f8b1501203d12027200d1f8d2209f0057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 4038, 'valid': 712}\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "\n",
    "normalize_img = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.RandomSizedCrop(image_size),\n",
    "    PowerPIL(),\n",
    "    transforms.ToTensor(),\n",
    "#     normalize_img,\n",
    "    RandomErasing()\n",
    "])\n",
    "\n",
    "## Normalization only for validation and test\n",
    "valid_trans = transforms.Compose([\n",
    "    transforms.Scale(256),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize_img\n",
    "])\n",
    "\n",
    "batch_size = 16\n",
    "train_data = df.sample(frac=0.85)\n",
    "valid_data = df[~df['file'].isin(train_data['file'])]\n",
    "\n",
    "train_set = BoneDataset(train_data, data_dir, transform = train_trans)\n",
    "valid_set = BoneDataset(valid_data, data_dir, transform = valid_trans)\n",
    "        \n",
    "\n",
    "t_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "v_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "# test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(t_loader.dataset), \n",
    "    'valid': len(v_loader.dataset)\n",
    "}\n",
    "\n",
    "print (dataset_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the DataLoader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0: \n",
      "i=1: \n",
      "i=2: \n",
      "i=3: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAABvCAYAAACjFLT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19947191cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagesToShow=4\n",
    "\n",
    "def flaotTensorToImage(img, mean=0, std=1):\n",
    "        \"\"\"convert a tensor to an image\"\"\"\n",
    "        img = np.transpose(img.numpy(), (1, 2, 0))\n",
    "        img = (img*std+ mean)*255\n",
    "        img = img.astype(np.uint8)    \n",
    "        return img    \n",
    "\n",
    "for i, data in enumerate(t_loader, 0):\n",
    "    print('i=%d: '%(i))            \n",
    "    images, labels = data            \n",
    "    num = len(images)\n",
    "    \n",
    "    ax = plt.subplot(1, imagesToShow, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    for n in range(num):\n",
    "        image=images[n]\n",
    "        label=labels[n]\n",
    "        plt.imshow (flaotTensorToImage(image))\n",
    "        \n",
    "    if i==imagesToShow-1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d966c8a9-d189-4b76-8def-6180f9498154",
    "_uuid": "fde155bdd9ce81e2598146c263cedfa65eaba806"
   },
   "source": [
    "## Define the model\n",
    "- A simple CNN with great performance (95% accuracy) \n",
    "- In PyTorch, a model is defined by a subclass of nn.Module. It has two methods:\n",
    "\n",
    "`__init__:` constructor. Create layers here. Note that we don't define the connections between layers in this function.\n",
    "\n",
    "`forward(x):` forward function. Receives an input variable x. Returns a output variable. Note that we actually connect the layers here dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "f2eb7b14-c63b-4fdf-8370-baabd48a9943",
    "_uuid": "29184efaeb75c7105b9f144550b68814c577534a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet (\n",
      "  (avgpool): AdaptiveAvgPool2d (output_size=1)\n",
      "  (cnn1): ConvCNN (\n",
      "    (math): Sequential (\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(2, 2))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (2): LeakyReLU (0.01)\n",
      "      (3): MaxPool2d (size=(4, 4), stride=(4, 4), dilation=(1, 1))\n",
      "    )\n",
      "    (avgpool): AvgPool2d (size=4, stride=4, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "  )\n",
      "  (cnn2): ConvCNN (\n",
      "    (math): Sequential (\n",
      "      (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (2): LeakyReLU (0.01)\n",
      "      (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    )\n",
      "    (avgpool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "  )\n",
      "  (cnn3): ConvCNN (\n",
      "    (math): Sequential (\n",
      "      (0): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (2): LeakyReLU (0.01)\n",
      "      (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    )\n",
      "    (avgpool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "  )\n",
      "  (res1): ConvRes (\n",
      "    (math): Sequential (\n",
      "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (1): Dropout (p = 0.3)\n",
      "      (2): Conv2d(256, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "      (3): PReLU (1)\n",
      "    )\n",
      "  )\n",
      "  (features): Sequential (\n",
      "    (0): ConvCNN (\n",
      "      (math): Sequential (\n",
      "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(2, 2))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (2): LeakyReLU (0.01)\n",
      "        (3): MaxPool2d (size=(4, 4), stride=(4, 4), dilation=(1, 1))\n",
      "      )\n",
      "      (avgpool): AvgPool2d (size=4, stride=4, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (1): Dropout (p = 0.3)\n",
      "    (2): ConvCNN (\n",
      "      (math): Sequential (\n",
      "        (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (2): LeakyReLU (0.01)\n",
      "        (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      )\n",
      "      (avgpool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (3): ConvCNN (\n",
      "      (math): Sequential (\n",
      "        (0): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (2): LeakyReLU (0.01)\n",
      "        (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      )\n",
      "      (avgpool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (4): ConvRes (\n",
      "      (math): Sequential (\n",
      "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (1): Dropout (p = 0.3)\n",
      "        (2): Conv2d(256, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "        (3): PReLU (1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential (\n",
      "    (0): Linear (2304 -> 12)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import math \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.30)\n",
    "relu=torch.nn.LeakyReLU()\n",
    "pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "class ConvRes(nn.Module):\n",
    "    def __init__(self,insize, outsize):\n",
    "        super(ConvRes, self).__init__()\n",
    "        drate = .3\n",
    "        self.math = nn.Sequential(\n",
    "                 nn.BatchNorm2d(insize),\n",
    "                 nn.Dropout(drate),\n",
    "                 torch.nn.Conv2d(insize, outsize, kernel_size=2,padding=2),\n",
    "                 nn.PReLU(),\n",
    "                )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.math(x) \n",
    "\n",
    "class ConvCNN(nn.Module):\n",
    "    def __init__(self,insize, outsize, kernel_size=7, padding=2, pool=2, avg=True):\n",
    "        super(ConvCNN, self).__init__()\n",
    "        self.avg=avg\n",
    "        self.math = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(insize, outsize, kernel_size=kernel_size,padding=padding),\n",
    "            torch.nn.BatchNorm2d(outsize),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d(pool,pool),\n",
    "        )\n",
    "        self.avgpool=torch.nn.AvgPool2d(pool,pool)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.math(x)\n",
    "        if self.avg is True:\n",
    "            x=self.avgpool(x)\n",
    "        return x   \n",
    "        \n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()        \n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.cnn1 = ConvCNN (3,64,  kernel_size=7, pool=4, avg=False)\n",
    "        self.cnn2 = ConvCNN (64,64, kernel_size=5, pool=2, avg=True)\n",
    "        self.cnn3 = ConvCNN (64,256, kernel_size=5, pool=2, avg=True)\n",
    "        \n",
    "        self.res1 = ConvRes (256,64)\n",
    "        \n",
    "        self.features = nn.Sequential( \n",
    "            self.cnn1,dropout,          \n",
    "            self.cnn2,\n",
    "            self.cnn3,\n",
    "            self.res1,\n",
    "        )        \n",
    "        \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            nn.Linear(2304, len(classes)),             \n",
    "        )\n",
    "#         self.sig=nn.Sigmoid()        \n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.features(x) \n",
    "        x = x.view(x.size(0), -1)        \n",
    "#         print (x.data.shape)\n",
    "        x = self.classifier(x)                \n",
    "#         x = self.sig(x)\n",
    "        return x        \n",
    "\n",
    "model = SimpleNet()\n",
    "# model = senetXX_generic(1, 3, 16)\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 0.00005 * 2 * 2)\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics and Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime \n",
    "try:\n",
    "    from pycrayon import CrayonClient\n",
    "except ImportError:\n",
    "    CrayonClient = None\n",
    "\n",
    "# tensorboad\n",
    "use_tensorboard = True\n",
    "# use_tensorboard = True and CrayonClient is not None\n",
    "\n",
    "if use_tensorboard == True:\n",
    "    cc = CrayonClient(hostname='http://192.168.1.2') # point to where you installed Crayon\n",
    "#     cc.remove_all_experiments()\n",
    "    \n",
    "model_name = (type(model).__name__)\n",
    "exp_name = datetime.datetime.now().strftime(model_name + '_' + 'bone' + '_%Y-%m-%d_%H-%M-%S')\n",
    "if use_tensorboard == True:\n",
    "    exp = cc.create_experiment(exp_name)    \n",
    "    \n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy2(y_pred, y_actual, topk=(1, )):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = y_actual.size(0)\n",
    "\n",
    "    _, pred = y_pred.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(y_actual.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0cd8c571-5d93-42b6-9ef0-9c16b6d43ef7",
    "_uuid": "1257d2cc10e64019a8ca94c814d4e179a45e04cd"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "f2cd5d63-c765-476a-9258-0152d8a06360",
    "_uuid": "d5ecfa57978ed8afd52e1551f6f5688ce9e16a5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "\n",
    "def train(train_loader, model, epoch, optimizer):\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "        criterion.cuda()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "   \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for batch_idx, (images, target) in enumerate(train_loader): \n",
    "        correct = 0\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            images, target = images.cuda(), target.cuda()\n",
    "            images, target = Variable(images), Variable(target)\n",
    "        # compute y_pred\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec1 = accuracy2(y_pred.data, target.data, topk=(1, 1))\n",
    "        losses.update(loss.data[0], images.size(0))\n",
    "        acc.update(prec1[0], images.size(0))\n",
    "        \n",
    "        pred = y_pred.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "        accuracy = 100. * correct / len(images)\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if batch_idx % 100  == 0:\n",
    "            print('TRAIN: LOSS-->{loss.val:.4f} ({loss.avg:.4f})\\t' 'ACC-->{acc.val:.3f}% ({acc.avg:.3f}%)'.format(loss=losses, acc=acc))\n",
    "            if use_tensorboard:\n",
    "                exp.add_scalar_value('tr_epoch_loss', losses.avg, step=epoch)\n",
    "                exp.add_scalar_value('tr_epoch_acc', acc.avg, step=epoch)\n",
    "                \n",
    "            print('TRAIN: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.3f}%)'.format(\n",
    "                epoch, batch_idx * len(images), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0],\n",
    "                correct, len(images),\n",
    "                accuracy))            \n",
    "    \n",
    "\n",
    "    return float('{loss.avg:.4f}'.format(loss=losses)), float('{acc.avg:.4f}'.format(acc=acc))\n",
    "\n",
    "def validate(val_loader, model, epoch):\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "        criterion.cuda()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, labels) in enumerate(val_loader):\n",
    "\n",
    "        if use_cuda:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            images, labels = Variable(images, volatile=True), Variable(labels)\n",
    "\n",
    "        # compute y_pred\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, labels)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, temp_var = accuracy2(y_pred.data, labels.data, topk=(1, 1))\n",
    "        losses.update(loss.data[0], images.size(0))\n",
    "        acc.update(prec1[0], images.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100== 0:\n",
    "            print('VAL:   LOSS--> {loss.val:.4f} ({loss.avg:.4f})\\t''ACC-->{acc.val:.3f} ({acc.avg:.3f})'.format(loss=losses, acc=acc))\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            if use_tensorboard:\n",
    "                exp.add_scalar_value('val_epoch_loss', losses.avg, step=epoch)\n",
    "                exp.add_scalar_value('val_epoch_acc', acc.avg, step=epoch)\n",
    "\n",
    "    print(' * Accuracy {acc.avg:.4f}'.format(acc=acc))\n",
    "    return float('{loss.avg:.6f}'.format(loss=losses)), float('{acc.avg:.6f}'.format(acc=acc))\n",
    "\n",
    "test_trans = valid_trans\n",
    "test_data_dir = 'd:/db/data/seedings/test/'\n",
    "\n",
    "def testImageLoader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "#     image = Image.open(image_name)\n",
    "    image = Image.open(image_name).convert('RGB')\n",
    "    image = test_trans(image)\n",
    "#     image = Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)  \n",
    "    if use_cuda:\n",
    "#         print (\"cuda\")\n",
    "        image.cuda()         \n",
    "    return image  \n",
    "\n",
    "def testModel(test_dir, local_model):    \n",
    "    if use_cuda:\n",
    "        local_model.cuda()\n",
    "    \n",
    "    local_model.eval()\n",
    "    \n",
    "    columns = ['file', 'species']\n",
    "    df_pred = pd.DataFrame(data=np.zeros((0, len(columns))), columns=columns)\n",
    "#     df_pred.species.astype(int)\n",
    "    for index, row in (sample_submission.iterrows()):\n",
    "#         for file in os.listdir(test_dir):            \n",
    "        currImage=os.path.join(test_dir, row['file'])\n",
    "        if os.path.isfile(currImage):\n",
    "            X_tensor_test=testImageLoader (currImage)            \n",
    "#             print (type(X_tensor_test))\n",
    "            if use_cuda:\n",
    "                X_tensor_test = Variable(X_tensor_test.cuda()) \n",
    "            else:\n",
    "                X_tensor_test = Variable(X_tensor_test)        \n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            predicted_val = (local_model(X_tensor_test)).data.max(1)[1] # get the index of the max log-probability\n",
    "#             predicted_val = predicted_val.data.max(1, keepdim=True)[1]\n",
    "            p_test = (predicted_val.cpu().numpy().item())\n",
    "            df_pred = df_pred.append({'file': row['file'], 'species': num_to_class[int(p_test)]}, ignore_index=True)             \n",
    "    \n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7b939262-bef9-4384-9e65-1c6f19b0e7af",
    "_uuid": "c89aec6e431baa5ad878aa07c30faef161dea697"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c75d0756-757e-4cdb-b3e3-43d0ae2110eb",
    "_uuid": "56b469e006382a0c93c7ce30b7976783257762b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: SimpleNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                      | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->2.4895 (2.4895)\tACC-->6.250% (6.250%)\n",
      "TRAIN: 0 [0/4038 (0%)]\tLoss: 2.489500, Accuracy: 1/16 (6.250%)\n",
      "TRAIN: LOSS-->2.4510 (2.2614)\tACC-->6.250% (23.267%)\n",
      "TRAIN: 0 [1600/4038 (40%)]\tLoss: 2.451027, Accuracy: 1/16 (6.250%)\n",
      "TRAIN: LOSS-->2.2205 (2.1660)\tACC-->25.000% (26.244%)\n",
      "TRAIN: 0 [3200/4038 (79%)]\tLoss: 2.220458, Accuracy: 4/16 (25.000%)\n",
      "VAL:   LOSS--> 1.6092 (1.6092)\tACC-->56.250 (56.250)\n",
      " * Accuracy 49.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                                           | 1/100 [00:56<1:33:41, 56.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.9055 (1.9055)\tACC-->31.250% (31.250%)\n",
      "TRAIN: 1 [0/4038 (0%)]\tLoss: 1.905538, Accuracy: 5/16 (31.250%)\n",
      "TRAIN: LOSS-->1.5526 (1.9118)\tACC-->62.500% (35.272%)\n",
      "TRAIN: 1 [1600/4038 (40%)]\tLoss: 1.552574, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.6025 (1.8652)\tACC-->43.750% (37.096%)\n",
      "TRAIN: 1 [3200/4038 (79%)]\tLoss: 1.602499, Accuracy: 7/16 (43.750%)\n",
      "VAL:   LOSS--> 1.7430 (1.7430)\tACC-->31.250 (31.250)\n",
      " * Accuracy 42.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▊                                                                                          | 2/100 [01:53<1:32:18, 56.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.3774 (1.3774)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 2 [0/4038 (0%)]\tLoss: 1.377430, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->2.0686 (1.7724)\tACC-->31.250% (38.738%)\n",
      "TRAIN: 2 [1600/4038 (40%)]\tLoss: 2.068565, Accuracy: 5/16 (31.250%)\n",
      "TRAIN: LOSS-->1.3171 (1.7642)\tACC-->50.000% (39.272%)\n",
      "TRAIN: 2 [3200/4038 (79%)]\tLoss: 1.317117, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 1.1959 (1.1959)\tACC-->75.000 (75.000)\n",
      " * Accuracy 51.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▊                                                                                         | 3/100 [02:48<1:30:50, 56.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->2.2369 (2.2369)\tACC-->37.500% (37.500%)\n",
      "TRAIN: 3 [0/4038 (0%)]\tLoss: 2.236871, Accuracy: 6/16 (37.500%)\n",
      "TRAIN: LOSS-->1.1125 (1.6900)\tACC-->56.250% (43.069%)\n",
      "TRAIN: 3 [1600/4038 (40%)]\tLoss: 1.112480, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.8811 (1.6831)\tACC-->31.250% (42.786%)\n",
      "TRAIN: 3 [3200/4038 (79%)]\tLoss: 1.881090, Accuracy: 5/16 (31.250%)\n",
      "VAL:   LOSS--> 1.3255 (1.3255)\tACC-->56.250 (56.250)\n",
      " * Accuracy 53.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▋                                                                                        | 4/100 [03:43<1:29:33, 55.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.5031 (1.5031)\tACC-->43.750% (43.750%)\n",
      "TRAIN: 4 [0/4038 (0%)]\tLoss: 1.503101, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.6074 (1.6599)\tACC-->43.750% (44.431%)\n",
      "TRAIN: 4 [1600/4038 (40%)]\tLoss: 1.607436, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.3741 (1.6418)\tACC-->62.500% (44.869%)\n",
      "TRAIN: 4 [3200/4038 (79%)]\tLoss: 1.374050, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.9969 (0.9969)\tACC-->68.750 (68.750)\n",
      " * Accuracy 65.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▌                                                                                       | 5/100 [04:39<1:28:26, 55.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.4814 (1.4814)\tACC-->43.750% (43.750%)\n",
      "TRAIN: 5 [0/4038 (0%)]\tLoss: 1.481438, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.6412 (1.5832)\tACC-->50.000% (45.854%)\n",
      "TRAIN: 5 [1600/4038 (40%)]\tLoss: 1.641160, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->1.4310 (1.5554)\tACC-->50.000% (47.046%)\n",
      "TRAIN: 5 [3200/4038 (79%)]\tLoss: 1.431048, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 1.1268 (1.1268)\tACC-->75.000 (75.000)\n",
      " * Accuracy 63.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████▌                                                                                      | 6/100 [05:34<1:27:22, 55.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->2.0029 (2.0029)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 6 [0/4038 (0%)]\tLoss: 2.002888, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.9933 (1.5809)\tACC-->43.750% (46.658%)\n",
      "TRAIN: 6 [1600/4038 (40%)]\tLoss: 1.993254, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.8942 (1.5553)\tACC-->37.500% (47.077%)\n",
      "TRAIN: 6 [3200/4038 (79%)]\tLoss: 1.894210, Accuracy: 6/16 (37.500%)\n",
      "VAL:   LOSS--> 1.0522 (1.0522)\tACC-->56.250 (56.250)\n",
      " * Accuracy 62.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██████▍                                                                                     | 7/100 [06:30<1:26:22, 55.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.3272 (1.3272)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 7 [0/4038 (0%)]\tLoss: 1.327225, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->1.3794 (1.4818)\tACC-->62.500% (51.795%)\n",
      "TRAIN: 7 [1600/4038 (40%)]\tLoss: 1.379379, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.5949 (1.5067)\tACC-->43.750% (50.062%)\n",
      "TRAIN: 7 [3200/4038 (79%)]\tLoss: 1.594914, Accuracy: 7/16 (43.750%)\n",
      "VAL:   LOSS--> 0.7263 (0.7263)\tACC-->81.250 (81.250)\n",
      " * Accuracy 70.787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███████▎                                                                                    | 8/100 [07:25<1:25:23, 55.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9316 (0.9316)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 8 [0/4038 (0%)]\tLoss: 0.931588, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.9160 (1.4134)\tACC-->62.500% (52.537%)\n",
      "TRAIN: 8 [1600/4038 (40%)]\tLoss: 0.915977, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.0910 (1.4146)\tACC-->75.000% (52.239%)\n",
      "TRAIN: 8 [3200/4038 (79%)]\tLoss: 1.090952, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.9586 (0.9586)\tACC-->62.500 (62.500)\n",
      " * Accuracy 76.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|████████▎                                                                                   | 9/100 [08:20<1:24:21, 55.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.2365 (1.2365)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 9 [0/4038 (0%)]\tLoss: 1.236490, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->1.1797 (1.3934)\tACC-->43.750% (53.960%)\n",
      "TRAIN: 9 [1600/4038 (40%)]\tLoss: 1.179683, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.2454 (1.3941)\tACC-->56.250% (53.700%)\n",
      "TRAIN: 9 [3200/4038 (79%)]\tLoss: 1.245373, Accuracy: 9/16 (56.250%)\n",
      "VAL:   LOSS--> 1.3553 (1.3553)\tACC-->62.500 (62.500)\n",
      " * Accuracy 58.287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█████████                                                                                  | 10/100 [09:15<1:23:23, 55.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.1847 (1.1847)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 10 [0/4038 (0%)]\tLoss: 1.184734, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.2686 (1.4341)\tACC-->68.750% (52.104%)\n",
      "TRAIN: 10 [1600/4038 (40%)]\tLoss: 1.268607, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.2859 (1.3798)\tACC-->50.000% (53.607%)\n",
      "TRAIN: 10 [3200/4038 (79%)]\tLoss: 1.285935, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 0.5212 (0.5212)\tACC-->75.000 (75.000)\n",
      " * Accuracy 76.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|██████████                                                                                 | 11/100 [10:11<1:22:25, 55.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.5314 (1.5314)\tACC-->37.500% (37.500%)\n",
      "TRAIN: 11 [0/4038 (0%)]\tLoss: 1.531422, Accuracy: 6/16 (37.500%)\n",
      "TRAIN: LOSS-->1.5580 (1.3351)\tACC-->43.750% (56.498%)\n",
      "TRAIN: 11 [1600/4038 (40%)]\tLoss: 1.557967, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.2087 (1.3306)\tACC-->50.000% (54.789%)\n",
      "TRAIN: 11 [3200/4038 (79%)]\tLoss: 1.208679, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 0.6129 (0.6129)\tACC-->75.000 (75.000)\n",
      " * Accuracy 78.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████▉                                                                                | 12/100 [11:06<1:21:27, 55.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.3742 (1.3742)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 12 [0/4038 (0%)]\tLoss: 1.374249, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->1.2481 (1.3131)\tACC-->43.750% (56.250%)\n",
      "TRAIN: 12 [1600/4038 (40%)]\tLoss: 1.248054, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.2215 (1.2768)\tACC-->62.500% (57.183%)\n",
      "TRAIN: 12 [3200/4038 (79%)]\tLoss: 1.221525, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.9558 (0.9558)\tACC-->62.500 (62.500)\n",
      " * Accuracy 73.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|███████████▊                                                                               | 13/100 [12:01<1:20:29, 55.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.4144 (1.4144)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 13 [0/4038 (0%)]\tLoss: 1.414353, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.3636 (1.2615)\tACC-->50.000% (59.344%)\n",
      "TRAIN: 13 [1600/4038 (40%)]\tLoss: 1.363605, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->1.5590 (1.2671)\tACC-->62.500% (58.831%)\n",
      "TRAIN: 13 [3200/4038 (79%)]\tLoss: 1.558952, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.7247 (0.7247)\tACC-->81.250 (81.250)\n",
      " * Accuracy 75.140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████████▋                                                                              | 14/100 [12:57<1:19:33, 55.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.5269 (1.5269)\tACC-->37.500% (37.500%)\n",
      "TRAIN: 14 [0/4038 (0%)]\tLoss: 1.526886, Accuracy: 6/16 (37.500%)\n",
      "TRAIN: LOSS-->0.8777 (1.2438)\tACC-->75.000% (58.725%)\n",
      "TRAIN: 14 [1600/4038 (40%)]\tLoss: 0.877673, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->1.1703 (1.2273)\tACC-->56.250% (59.204%)\n",
      "TRAIN: 14 [3200/4038 (79%)]\tLoss: 1.170338, Accuracy: 9/16 (56.250%)\n",
      "VAL:   LOSS--> 0.3597 (0.3597)\tACC-->93.750 (93.750)\n",
      " * Accuracy 81.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████████████▋                                                                             | 15/100 [13:52<1:18:36, 55.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.4404 (1.4404)\tACC-->37.500% (37.500%)\n",
      "TRAIN: 15 [0/4038 (0%)]\tLoss: 1.440440, Accuracy: 6/16 (37.500%)\n",
      "TRAIN: LOSS-->1.7634 (1.3329)\tACC-->31.250% (55.260%)\n",
      "TRAIN: 15 [1600/4038 (40%)]\tLoss: 1.763407, Accuracy: 5/16 (31.250%)\n",
      "TRAIN: LOSS-->1.7307 (1.2687)\tACC-->43.750% (56.934%)\n",
      "TRAIN: 15 [3200/4038 (79%)]\tLoss: 1.730715, Accuracy: 7/16 (43.750%)\n",
      "VAL:   LOSS--> 0.3970 (0.3970)\tACC-->93.750 (93.750)\n",
      " * Accuracy 81.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████████████▌                                                                            | 16/100 [14:47<1:17:39, 55.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.6242 (1.6242)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 16 [0/4038 (0%)]\tLoss: 1.624245, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.4057 (1.1991)\tACC-->50.000% (58.787%)\n",
      "TRAIN: 16 [1600/4038 (40%)]\tLoss: 1.405683, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->0.7478 (1.1899)\tACC-->81.250% (59.204%)\n",
      "TRAIN: 16 [3200/4038 (79%)]\tLoss: 0.747773, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.4894 (0.4894)\tACC-->87.500 (87.500)\n",
      " * Accuracy 84.410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████████████▍                                                                           | 17/100 [15:42<1:16:42, 55.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.2949 (1.2949)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 17 [0/4038 (0%)]\tLoss: 1.294885, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.0052 (1.1917)\tACC-->50.000% (60.582%)\n",
      "TRAIN: 17 [1600/4038 (40%)]\tLoss: 1.005242, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->2.1678 (1.1900)\tACC-->37.500% (59.670%)\n",
      "TRAIN: 17 [3200/4038 (79%)]\tLoss: 2.167773, Accuracy: 6/16 (37.500%)\n",
      "VAL:   LOSS--> 0.3567 (0.3567)\tACC-->93.750 (93.750)\n",
      " * Accuracy 82.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|████████████████▍                                                                          | 18/100 [16:37<1:15:46, 55.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.1097 (1.1097)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 18 [0/4038 (0%)]\tLoss: 1.109674, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.1241 (1.1349)\tACC-->68.750% (61.696%)\n",
      "TRAIN: 18 [1600/4038 (40%)]\tLoss: 1.124138, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.3298 (1.1756)\tACC-->62.500% (60.759%)\n",
      "TRAIN: 18 [3200/4038 (79%)]\tLoss: 1.329812, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.6568 (0.6568)\tACC-->62.500 (62.500)\n",
      " * Accuracy 80.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█████████████████▎                                                                         | 19/100 [17:33<1:14:49, 55.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6755 (0.6755)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 19 [0/4038 (0%)]\tLoss: 0.675526, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->1.1331 (1.1504)\tACC-->56.250% (60.767%)\n",
      "TRAIN: 19 [1600/4038 (40%)]\tLoss: 1.133104, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.9811 (1.1626)\tACC-->75.000% (61.381%)\n",
      "TRAIN: 19 [3200/4038 (79%)]\tLoss: 0.981052, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.6736 (0.6736)\tACC-->75.000 (75.000)\n",
      " * Accuracy 79.073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████████▏                                                                        | 20/100 [18:28<1:13:53, 55.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.1374 (1.1374)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 20 [0/4038 (0%)]\tLoss: 1.137379, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.9866 (1.1385)\tACC-->68.750% (61.696%)\n",
      "TRAIN: 20 [1600/4038 (40%)]\tLoss: 0.986641, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.9465 (1.1114)\tACC-->68.750% (63.215%)\n",
      "TRAIN: 20 [3200/4038 (79%)]\tLoss: 0.946544, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.4966 (0.4966)\tACC-->81.250 (81.250)\n",
      " * Accuracy 82.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|███████████████████                                                                        | 21/100 [19:23<1:12:56, 55.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9218 (0.9218)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 21 [0/4038 (0%)]\tLoss: 0.921780, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.7287 (1.0588)\tACC-->75.000% (64.975%)\n",
      "TRAIN: 21 [1600/4038 (40%)]\tLoss: 0.728657, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.8536 (1.0808)\tACC-->68.750% (63.961%)\n",
      "TRAIN: 21 [3200/4038 (79%)]\tLoss: 0.853606, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.3982 (0.3982)\tACC-->81.250 (81.250)\n",
      " * Accuracy 73.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|████████████████████                                                                       | 22/100 [20:18<1:12:00, 55.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0219 (1.0219)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 22 [0/4038 (0%)]\tLoss: 1.021912, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.9718 (1.0533)\tACC-->62.500% (64.542%)\n",
      "TRAIN: 22 [1600/4038 (40%)]\tLoss: 0.971820, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.3702 (1.0955)\tACC-->56.250% (62.842%)\n",
      "TRAIN: 22 [3200/4038 (79%)]\tLoss: 1.370190, Accuracy: 9/16 (56.250%)\n",
      "VAL:   LOSS--> 0.2337 (0.2337)\tACC-->93.750 (93.750)\n",
      " * Accuracy 82.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|████████████████████▉                                                                      | 23/100 [21:13<1:11:03, 55.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.3370 (1.3370)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 23 [0/4038 (0%)]\tLoss: 1.337022, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->0.5670 (1.0547)\tACC-->75.000% (64.171%)\n",
      "TRAIN: 23 [1600/4038 (40%)]\tLoss: 0.566956, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->1.0203 (1.0625)\tACC-->50.000% (64.583%)\n",
      "TRAIN: 23 [3200/4038 (79%)]\tLoss: 1.020285, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 0.6312 (0.6312)\tACC-->87.500 (87.500)\n",
      " * Accuracy 84.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|█████████████████████▊                                                                     | 24/100 [22:08<1:10:07, 55.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9672 (0.9672)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 24 [0/4038 (0%)]\tLoss: 0.967186, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->1.4598 (1.0783)\tACC-->56.250% (62.624%)\n",
      "TRAIN: 24 [1600/4038 (40%)]\tLoss: 1.459803, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.9340 (1.0834)\tACC-->75.000% (63.371%)\n",
      "TRAIN: 24 [3200/4038 (79%)]\tLoss: 0.934038, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.6301 (0.6301)\tACC-->81.250 (81.250)\n",
      " * Accuracy 84.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██████████████████████▊                                                                    | 25/100 [23:03<1:09:11, 55.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.1829 (1.1829)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 25 [0/4038 (0%)]\tLoss: 1.182856, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.2928 (1.0638)\tACC-->50.000% (65.037%)\n",
      "TRAIN: 25 [1600/4038 (40%)]\tLoss: 1.292767, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->0.5994 (1.0400)\tACC-->87.500% (64.832%)\n",
      "TRAIN: 25 [3200/4038 (79%)]\tLoss: 0.599448, Accuracy: 14/16 (87.500%)\n",
      "VAL:   LOSS--> 0.2340 (0.2340)\tACC-->100.000 (100.000)\n",
      " * Accuracy 85.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|███████████████████████▋                                                                   | 26/100 [23:59<1:08:15, 55.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9446 (0.9446)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 26 [0/4038 (0%)]\tLoss: 0.944636, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.7321 (0.9742)\tACC-->68.750% (65.347%)\n",
      "TRAIN: 26 [1600/4038 (40%)]\tLoss: 0.732089, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.1411 (1.0027)\tACC-->62.500% (65.392%)\n",
      "TRAIN: 26 [3200/4038 (79%)]\tLoss: 1.141116, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.4128 (0.4128)\tACC-->81.250 (81.250)\n",
      " * Accuracy 84.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|████████████████████████▌                                                                  | 27/100 [24:54<1:07:19, 55.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0159 (1.0159)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 27 [0/4038 (0%)]\tLoss: 1.015893, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.3727 (1.0523)\tACC-->56.250% (64.418%)\n",
      "TRAIN: 27 [1600/4038 (40%)]\tLoss: 1.372718, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.7023 (1.0462)\tACC-->81.250% (64.801%)\n",
      "TRAIN: 27 [3200/4038 (79%)]\tLoss: 0.702273, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.2902 (0.2902)\tACC-->75.000 (75.000)\n",
      " * Accuracy 85.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|█████████████████████████▍                                                                 | 28/100 [25:49<1:06:24, 55.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9259 (0.9259)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 28 [0/4038 (0%)]\tLoss: 0.925875, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->1.0910 (1.0289)\tACC-->56.250% (65.780%)\n",
      "TRAIN: 28 [1600/4038 (40%)]\tLoss: 1.090990, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.8440 (1.0165)\tACC-->75.000% (66.169%)\n",
      "TRAIN: 28 [3200/4038 (79%)]\tLoss: 0.843998, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.3429 (0.3429)\tACC-->75.000 (75.000)\n",
      " * Accuracy 82.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██████████████████████████▍                                                                | 29/100 [26:44<1:05:28, 55.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.3388 (1.3388)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 29 [0/4038 (0%)]\tLoss: 1.338789, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.1037 (0.9974)\tACC-->75.000% (67.017%)\n",
      "TRAIN: 29 [1600/4038 (40%)]\tLoss: 1.103721, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.7421 (0.9890)\tACC-->81.250% (66.947%)\n",
      "TRAIN: 29 [3200/4038 (79%)]\tLoss: 0.742091, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.3738 (0.3738)\tACC-->87.500 (87.500)\n",
      " * Accuracy 83.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████████▎                                                               | 30/100 [27:40<1:04:34, 55.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.2837 (1.2837)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 30 [0/4038 (0%)]\tLoss: 1.283724, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.8764 (0.9919)\tACC-->43.750% (66.832%)\n",
      "TRAIN: 30 [1600/4038 (40%)]\tLoss: 1.876415, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->0.5675 (0.9985)\tACC-->75.000% (65.889%)\n",
      "TRAIN: 30 [3200/4038 (79%)]\tLoss: 0.567523, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.3007 (0.3007)\tACC-->93.750 (93.750)\n",
      " * Accuracy 83.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████████▏                                                              | 31/100 [28:37<1:03:42, 55.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.8505 (0.8505)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 31 [0/4038 (0%)]\tLoss: 0.850512, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.7567 (0.9348)\tACC-->75.000% (69.493%)\n",
      "TRAIN: 31 [1600/4038 (40%)]\tLoss: 0.756653, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.6916 (0.9701)\tACC-->87.500% (67.226%)\n",
      "TRAIN: 31 [3200/4038 (79%)]\tLoss: 0.691632, Accuracy: 14/16 (87.500%)\n",
      "VAL:   LOSS--> 0.7795 (0.7795)\tACC-->75.000 (75.000)\n",
      " * Accuracy 77.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████████                                                              | 32/100 [29:33<1:02:48, 55.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.1316 (1.1316)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 32 [0/4038 (0%)]\tLoss: 1.131637, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.5981 (0.9571)\tACC-->68.750% (67.017%)\n",
      "TRAIN: 32 [1600/4038 (40%)]\tLoss: 0.598109, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.9873 (0.9517)\tACC-->75.000% (67.693%)\n",
      "TRAIN: 32 [3200/4038 (79%)]\tLoss: 0.987340, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.3412 (0.3412)\tACC-->87.500 (87.500)\n",
      " * Accuracy 88.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████████                                                             | 33/100 [30:32<1:02:00, 55.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.3720 (1.3720)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 33 [0/4038 (0%)]\tLoss: 1.372031, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.7982 (1.0067)\tACC-->62.500% (65.161%)\n",
      "TRAIN: 33 [1600/4038 (40%)]\tLoss: 0.798177, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.6863 (0.9528)\tACC-->31.250% (67.040%)\n",
      "TRAIN: 33 [3200/4038 (79%)]\tLoss: 1.686282, Accuracy: 5/16 (31.250%)\n",
      "VAL:   LOSS--> 0.2394 (0.2394)\tACC-->93.750 (93.750)\n",
      " * Accuracy 89.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████████████████▉                                                            | 34/100 [31:32<1:01:13, 55.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0416 (1.0416)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 34 [0/4038 (0%)]\tLoss: 1.041565, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.8175 (0.9343)\tACC-->75.000% (68.688%)\n",
      "TRAIN: 34 [1600/4038 (40%)]\tLoss: 0.817534, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.5574 (0.9328)\tACC-->87.500% (68.501%)\n",
      "TRAIN: 34 [3200/4038 (79%)]\tLoss: 0.557442, Accuracy: 14/16 (87.500%)\n",
      "VAL:   LOSS--> 0.1979 (0.1979)\tACC-->93.750 (93.750)\n",
      " * Accuracy 84.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████████████████████▊                                                           | 35/100 [32:27<1:00:17, 55.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.2359 (1.2359)\tACC-->43.750% (43.750%)\n",
      "TRAIN: 35 [0/4038 (0%)]\tLoss: 1.235933, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->0.9611 (0.9551)\tACC-->62.500% (68.317%)\n",
      "TRAIN: 35 [1600/4038 (40%)]\tLoss: 0.961108, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.9624 (0.9593)\tACC-->62.500% (67.786%)\n",
      "TRAIN: 35 [3200/4038 (79%)]\tLoss: 0.962366, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.5652 (0.5652)\tACC-->87.500 (87.500)\n",
      " * Accuracy 88.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████████▍                                                           | 36/100 [33:23<59:21, 55.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0521 (1.0521)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 36 [0/4038 (0%)]\tLoss: 1.052097, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.4177 (0.8848)\tACC-->50.000% (70.421%)\n",
      "TRAIN: 36 [1600/4038 (40%)]\tLoss: 1.417675, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->0.9977 (0.9019)\tACC-->75.000% (69.590%)\n",
      "TRAIN: 36 [3200/4038 (79%)]\tLoss: 0.997689, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.1770 (0.1770)\tACC-->93.750 (93.750)\n",
      " * Accuracy 88.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████████▍                                                          | 37/100 [34:18<58:25, 55.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6781 (0.6781)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 37 [0/4038 (0%)]\tLoss: 0.678118, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->1.0111 (0.8934)\tACC-->56.250% (69.616%)\n",
      "TRAIN: 37 [1600/4038 (40%)]\tLoss: 1.011118, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.9717 (0.8970)\tACC-->75.000% (69.216%)\n",
      "TRAIN: 37 [3200/4038 (79%)]\tLoss: 0.971654, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.4407 (0.4407)\tACC-->81.250 (81.250)\n",
      " * Accuracy 85.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████████▎                                                         | 38/100 [35:14<57:29, 55.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7396 (0.7396)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 38 [0/4038 (0%)]\tLoss: 0.739560, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->1.2437 (0.9126)\tACC-->50.000% (68.626%)\n",
      "TRAIN: 38 [1600/4038 (40%)]\tLoss: 1.243719, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->1.1901 (0.9176)\tACC-->50.000% (68.439%)\n",
      "TRAIN: 38 [3200/4038 (79%)]\tLoss: 1.190117, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 0.4842 (0.4842)\tACC-->81.250 (81.250)\n",
      " * Accuracy 88.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|████████████████████████████████████▎                                                        | 39/100 [36:15<56:42, 55.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6488 (0.6488)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 39 [0/4038 (0%)]\tLoss: 0.648763, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.9609 (0.8852)\tACC-->68.750% (68.998%)\n",
      "TRAIN: 39 [1600/4038 (40%)]\tLoss: 0.960933, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.0307 (0.8978)\tACC-->81.250% (68.843%)\n",
      "TRAIN: 39 [3200/4038 (79%)]\tLoss: 1.030748, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.6062 (0.6062)\tACC-->81.250 (81.250)\n",
      " * Accuracy 86.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████████▏                                                       | 40/100 [37:17<55:56, 55.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0767 (1.0767)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 40 [0/4038 (0%)]\tLoss: 1.076732, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.6478 (0.9099)\tACC-->81.250% (68.812%)\n",
      "TRAIN: 40 [1600/4038 (40%)]\tLoss: 0.647781, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.8642 (0.8989)\tACC-->62.500% (68.657%)\n",
      "TRAIN: 40 [3200/4038 (79%)]\tLoss: 0.864171, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.3389 (0.3389)\tACC-->87.500 (87.500)\n",
      " * Accuracy 86.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|██████████████████████████████████████▏                                                      | 41/100 [38:20<55:10, 56.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.4191 (1.4191)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 41 [0/4038 (0%)]\tLoss: 1.419096, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->0.5351 (0.9252)\tACC-->87.500% (68.812%)\n",
      "TRAIN: 41 [1600/4038 (40%)]\tLoss: 0.535053, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.7420 (0.9155)\tACC-->81.250% (68.905%)\n",
      "TRAIN: 41 [3200/4038 (79%)]\tLoss: 0.742021, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.2390 (0.2390)\tACC-->87.500 (87.500)\n",
      " * Accuracy 86.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████████████████████████                                                      | 42/100 [39:24<54:24, 56.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5095 (0.5095)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 42 [0/4038 (0%)]\tLoss: 0.509506, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.9434 (0.8896)\tACC-->68.750% (69.431%)\n",
      "TRAIN: 42 [1600/4038 (40%)]\tLoss: 0.943355, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.9391 (0.8893)\tACC-->75.000% (68.937%)\n",
      "TRAIN: 42 [3200/4038 (79%)]\tLoss: 0.939074, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.1979 (0.1979)\tACC-->100.000 (100.000)\n",
      " * Accuracy 88.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|███████████████████████████████████████▉                                                     | 43/100 [40:24<53:34, 56.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6776 (0.6776)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 43 [0/4038 (0%)]\tLoss: 0.677644, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.7962 (0.8436)\tACC-->68.750% (71.287%)\n",
      "TRAIN: 43 [1600/4038 (40%)]\tLoss: 0.796200, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.1529 (0.8653)\tACC-->68.750% (70.989%)\n",
      "TRAIN: 43 [3200/4038 (79%)]\tLoss: 1.152855, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.3218 (0.3218)\tACC-->93.750 (93.750)\n",
      " * Accuracy 91.573\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████████▉                                                    | 44/100 [41:33<52:53, 56.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.8768 (0.8768)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 44 [0/4038 (0%)]\tLoss: 0.876779, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.6169 (0.8394)\tACC-->81.250% (70.606%)\n",
      "TRAIN: 44 [1600/4038 (40%)]\tLoss: 0.616894, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.6399 (0.8587)\tACC-->75.000% (69.932%)\n",
      "TRAIN: 44 [3200/4038 (79%)]\tLoss: 0.639872, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.5330 (0.5330)\tACC-->81.250 (81.250)\n",
      " * Accuracy 89.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████████▊                                                   | 45/100 [42:37<52:05, 56.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0418 (1.0418)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 45 [0/4038 (0%)]\tLoss: 1.041841, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.3963 (0.8475)\tACC-->87.500% (71.782%)\n",
      "TRAIN: 45 [1600/4038 (40%)]\tLoss: 0.396277, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.6405 (0.8403)\tACC-->75.000% (71.766%)\n",
      "TRAIN: 45 [3200/4038 (79%)]\tLoss: 0.640501, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.1975 (0.1975)\tACC-->93.750 (93.750)\n",
      " * Accuracy 90.449\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|██████████████████████████████████████████▊                                                  | 46/100 [43:45<51:21, 57.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6008 (0.6008)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 46 [0/4038 (0%)]\tLoss: 0.600772, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.8173 (0.8604)\tACC-->68.750% (70.421%)\n",
      "TRAIN: 46 [1600/4038 (40%)]\tLoss: 0.817291, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.2991 (0.8510)\tACC-->56.250% (71.051%)\n",
      "TRAIN: 46 [3200/4038 (79%)]\tLoss: 1.299067, Accuracy: 9/16 (56.250%)\n",
      "VAL:   LOSS--> 0.1068 (0.1068)\tACC-->100.000 (100.000)\n",
      " * Accuracy 86.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████████████████████████████▋                                                 | 47/100 [44:50<50:33, 57.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9151 (0.9151)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 47 [0/4038 (0%)]\tLoss: 0.915098, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.5878 (0.8360)\tACC-->75.000% (71.411%)\n",
      "TRAIN: 47 [1600/4038 (40%)]\tLoss: 0.587843, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.8808 (0.8293)\tACC-->75.000% (71.984%)\n",
      "TRAIN: 47 [3200/4038 (79%)]\tLoss: 0.880766, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.4289 (0.4289)\tACC-->81.250 (81.250)\n",
      " * Accuracy 89.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████████████████████████████████████████████▋                                                | 48/100 [45:55<49:45, 57.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.2685 (1.2685)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 48 [0/4038 (0%)]\tLoss: 1.268461, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.6331 (0.8593)\tACC-->81.250% (71.040%)\n",
      "TRAIN: 48 [1600/4038 (40%)]\tLoss: 0.633121, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.7662 (0.8387)\tACC-->81.250% (71.953%)\n",
      "TRAIN: 48 [3200/4038 (79%)]\tLoss: 0.766173, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.2545 (0.2545)\tACC-->93.750 (93.750)\n",
      " * Accuracy 91.713\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|█████████████████████████████████████████████▌                                               | 49/100 [47:04<49:00, 57.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5406 (0.5406)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 49 [0/4038 (0%)]\tLoss: 0.540597, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.7300 (0.8089)\tACC-->75.000% (72.153%)\n",
      "TRAIN: 49 [1600/4038 (40%)]\tLoss: 0.730020, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.6531 (0.8226)\tACC-->75.000% (71.549%)\n",
      "TRAIN: 49 [3200/4038 (79%)]\tLoss: 0.653054, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.1441 (0.1441)\tACC-->100.000 (100.000)\n",
      " * Accuracy 88.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████████▌                                              | 50/100 [48:12<48:12, 57.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.8899 (0.8899)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 50 [0/4038 (0%)]\tLoss: 0.889885, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.1831 (0.8254)\tACC-->62.500% (72.030%)\n",
      "TRAIN: 50 [1600/4038 (40%)]\tLoss: 1.183147, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.2151 (0.8201)\tACC-->50.000% (71.797%)\n",
      "TRAIN: 50 [3200/4038 (79%)]\tLoss: 1.215069, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 0.1980 (0.1980)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.152\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|███████████████████████████████████████████████▍                                             | 51/100 [49:25<47:29, 58.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4132 (0.4132)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 51 [0/4038 (0%)]\tLoss: 0.413223, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.5692 (0.8171)\tACC-->81.250% (72.339%)\n",
      "TRAIN: 51 [1600/4038 (40%)]\tLoss: 0.569238, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->1.4294 (0.8034)\tACC-->62.500% (72.233%)\n",
      "TRAIN: 51 [3200/4038 (79%)]\tLoss: 1.429351, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.0598 (0.0598)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.573\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|████████████████████████████████████████████████▎                                            | 52/100 [50:37<46:43, 58.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9734 (0.9734)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 52 [0/4038 (0%)]\tLoss: 0.973414, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.4696 (0.8019)\tACC-->50.000% (72.710%)\n",
      "TRAIN: 52 [1600/4038 (40%)]\tLoss: 1.469574, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->0.7818 (0.7959)\tACC-->75.000% (72.108%)\n",
      "TRAIN: 52 [3200/4038 (79%)]\tLoss: 0.781834, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.2477 (0.2477)\tACC-->93.750 (93.750)\n",
      " * Accuracy 91.011\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████████████████▎                                           | 53/100 [51:45<45:53, 58.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6763 (0.6763)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 53 [0/4038 (0%)]\tLoss: 0.676270, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.6680 (0.7957)\tACC-->87.500% (73.700%)\n",
      "TRAIN: 53 [1600/4038 (40%)]\tLoss: 0.667981, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.4584 (0.7834)\tACC-->87.500% (72.699%)\n",
      "TRAIN: 53 [3200/4038 (79%)]\tLoss: 0.458350, Accuracy: 14/16 (87.500%)\n",
      "VAL:   LOSS--> 0.1413 (0.1413)\tACC-->93.750 (93.750)\n",
      " * Accuracy 90.449\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████████████▏                                          | 54/100 [52:54<45:04, 58.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0238 (1.0238)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 54 [0/4038 (0%)]\tLoss: 1.023795, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.4716 (0.8058)\tACC-->87.500% (71.287%)\n",
      "TRAIN: 54 [1600/4038 (40%)]\tLoss: 0.471588, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->1.3447 (0.8129)\tACC-->43.750% (72.326%)\n",
      "TRAIN: 54 [3200/4038 (79%)]\tLoss: 1.344683, Accuracy: 7/16 (43.750%)\n",
      "VAL:   LOSS--> 0.3242 (0.3242)\tACC-->93.750 (93.750)\n",
      " * Accuracy 91.713\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████████████▏                                         | 55/100 [54:04<44:14, 58.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5075 (0.5075)\tACC-->93.750% (93.750%)\n",
      "TRAIN: 55 [0/4038 (0%)]\tLoss: 0.507530, Accuracy: 15/16 (93.750%)\n",
      "TRAIN: LOSS-->0.4909 (0.8242)\tACC-->87.500% (72.463%)\n",
      "TRAIN: 55 [1600/4038 (40%)]\tLoss: 0.490878, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.2797 (0.7774)\tACC-->100.000% (73.476%)\n",
      "TRAIN: 55 [3200/4038 (79%)]\tLoss: 0.279661, Accuracy: 16/16 (100.000%)\n",
      "VAL:   LOSS--> 0.1126 (0.1126)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.135\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████████████                                         | 56/100 [55:13<43:23, 59.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.8553 (0.8553)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 56 [0/4038 (0%)]\tLoss: 0.855313, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.7085 (0.7687)\tACC-->81.250% (74.319%)\n",
      "TRAIN: 56 [1600/4038 (40%)]\tLoss: 0.708529, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.4424 (0.7920)\tACC-->81.250% (73.259%)\n",
      "TRAIN: 56 [3200/4038 (79%)]\tLoss: 0.442365, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.1225 (0.1225)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.011\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████████████                                        | 57/100 [56:22<42:31, 59.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6689 (0.6689)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 57 [0/4038 (0%)]\tLoss: 0.668852, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.9431 (0.8080)\tACC-->68.750% (71.658%)\n",
      "TRAIN: 57 [1600/4038 (40%)]\tLoss: 0.943116, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.7935 (0.7840)\tACC-->68.750% (72.637%)\n",
      "TRAIN: 57 [3200/4038 (79%)]\tLoss: 0.793494, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.4181 (0.4181)\tACC-->81.250 (81.250)\n",
      " * Accuracy 88.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████████████████████████████████████████████████████▉                                       | 58/100 [57:23<41:33, 59.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7804 (0.7804)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 58 [0/4038 (0%)]\tLoss: 0.780435, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.4955 (0.7824)\tACC-->87.500% (74.319%)\n",
      "TRAIN: 58 [1600/4038 (40%)]\tLoss: 0.495517, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.8673 (0.7559)\tACC-->68.750% (73.850%)\n",
      "TRAIN: 58 [3200/4038 (79%)]\tLoss: 0.867339, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.6672 (0.6672)\tACC-->87.500 (87.500)\n",
      " * Accuracy 92.697\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|██████████████████████████████████████████████████████▊                                      | 59/100 [58:27<40:37, 59.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6570 (0.6570)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 59 [0/4038 (0%)]\tLoss: 0.656991, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.7278 (0.8086)\tACC-->75.000% (72.710%)\n",
      "TRAIN: 59 [1600/4038 (40%)]\tLoss: 0.727798, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.5209 (0.7751)\tACC-->81.250% (73.725%)\n",
      "TRAIN: 59 [3200/4038 (79%)]\tLoss: 0.520929, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.1249 (0.1249)\tACC-->93.750 (93.750)\n",
      " * Accuracy 90.169\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████████████▊                                     | 60/100 [59:35<39:43, 59.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7482 (0.7482)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 60 [0/4038 (0%)]\tLoss: 0.748187, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.7737 (0.7997)\tACC-->75.000% (72.896%)\n",
      "TRAIN: 60 [1600/4038 (40%)]\tLoss: 0.773706, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.4556 (0.7669)\tACC-->81.250% (74.254%)\n",
      "TRAIN: 60 [3200/4038 (79%)]\tLoss: 0.455621, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.1246 (0.1246)\tACC-->93.750 (93.750)\n",
      " * Accuracy 93.820\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|███████████████████████████████████████████████████████▌                                   | 61/100 [1:00:45<38:50, 59.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7814 (0.7814)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 61 [0/4038 (0%)]\tLoss: 0.781408, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.5382 (0.7732)\tACC-->81.250% (73.886%)\n",
      "TRAIN: 61 [1600/4038 (40%)]\tLoss: 0.538176, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->1.2126 (0.7797)\tACC-->62.500% (72.886%)\n",
      "TRAIN: 61 [3200/4038 (79%)]\tLoss: 1.212572, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.2113 (0.2113)\tACC-->93.750 (93.750)\n",
      " * Accuracy 90.730\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|████████████████████████████████████████████████████████▍                                  | 62/100 [1:01:55<37:56, 59.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.2988 (1.2988)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 62 [0/4038 (0%)]\tLoss: 1.298784, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->0.7417 (0.7729)\tACC-->81.250% (74.010%)\n",
      "TRAIN: 62 [1600/4038 (40%)]\tLoss: 0.741743, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.6259 (0.7466)\tACC-->81.250% (74.813%)\n",
      "TRAIN: 62 [3200/4038 (79%)]\tLoss: 0.625874, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.2520 (0.2520)\tACC-->81.250 (81.250)\n",
      " * Accuracy 89.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|█████████████████████████████████████████████████████████▎                                 | 63/100 [1:02:56<36:57, 59.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3757 (0.3757)\tACC-->93.750% (93.750%)\n",
      "TRAIN: 63 [0/4038 (0%)]\tLoss: 0.375733, Accuracy: 15/16 (93.750%)\n",
      "TRAIN: LOSS-->0.5736 (0.7471)\tACC-->75.000% (73.700%)\n",
      "TRAIN: 63 [1600/4038 (40%)]\tLoss: 0.573641, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.8306 (0.7465)\tACC-->68.750% (74.502%)\n",
      "TRAIN: 63 [3200/4038 (79%)]\tLoss: 0.830578, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.2259 (0.2259)\tACC-->87.500 (87.500)\n",
      " * Accuracy 91.433\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████████████████████████████████████▏                                | 64/100 [1:04:02<36:01, 60.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4702 (0.4702)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 64 [0/4038 (0%)]\tLoss: 0.470214, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.7080 (0.7425)\tACC-->75.000% (75.062%)\n",
      "TRAIN: 64 [1600/4038 (40%)]\tLoss: 0.708001, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.3276 (0.7563)\tACC-->93.750% (75.373%)\n",
      "TRAIN: 64 [3200/4038 (79%)]\tLoss: 0.327640, Accuracy: 15/16 (93.750%)\n",
      "VAL:   LOSS--> 0.1408 (0.1408)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.994\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████████████████████████████████████▏                               | 65/100 [1:05:07<35:04, 60.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7173 (0.7173)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 65 [0/4038 (0%)]\tLoss: 0.717347, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.5531 (0.7209)\tACC-->87.500% (75.990%)\n",
      "TRAIN: 65 [1600/4038 (40%)]\tLoss: 0.553063, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.8806 (0.7119)\tACC-->75.000% (76.182%)\n",
      "TRAIN: 65 [3200/4038 (79%)]\tLoss: 0.880599, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.5163 (0.5163)\tACC-->81.250 (81.250)\n",
      " * Accuracy 89.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████████████                               | 66/100 [1:06:11<34:05, 60.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4919 (0.4919)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 66 [0/4038 (0%)]\tLoss: 0.491921, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.2486 (0.7536)\tACC-->100.000% (73.886%)\n",
      "TRAIN: 66 [1600/4038 (40%)]\tLoss: 0.248591, Accuracy: 16/16 (100.000%)\n",
      "TRAIN: LOSS-->0.9330 (0.7573)\tACC-->68.750% (73.881%)\n",
      "TRAIN: 66 [3200/4038 (79%)]\tLoss: 0.933006, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.2123 (0.2123)\tACC-->93.750 (93.750)\n",
      " * Accuracy 91.011\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████████▉                              | 67/100 [1:07:17<33:08, 60.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4423 (0.4423)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 67 [0/4038 (0%)]\tLoss: 0.442259, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.5946 (0.7151)\tACC-->68.750% (76.052%)\n",
      "TRAIN: 67 [1600/4038 (40%)]\tLoss: 0.594611, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.9132 (0.7709)\tACC-->62.500% (74.160%)\n",
      "TRAIN: 67 [3200/4038 (79%)]\tLoss: 0.913166, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.5682 (0.5682)\tACC-->75.000 (75.000)\n",
      " * Accuracy 91.994\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|█████████████████████████████████████████████████████████████▉                             | 68/100 [1:08:24<32:11, 60.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7412 (0.7412)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 68 [0/4038 (0%)]\tLoss: 0.741227, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.3837 (0.7382)\tACC-->81.250% (73.391%)\n",
      "TRAIN: 68 [1600/4038 (40%)]\tLoss: 0.383696, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.5409 (0.7310)\tACC-->75.000% (73.694%)\n",
      "TRAIN: 68 [3200/4038 (79%)]\tLoss: 0.540949, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.2026 (0.2026)\tACC-->81.250 (81.250)\n",
      " * Accuracy 91.713\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████████████████████████████████████████████████████████████▊                            | 69/100 [1:09:32<31:14, 60.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5286 (0.5286)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 69 [0/4038 (0%)]\tLoss: 0.528647, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->1.0887 (0.6893)\tACC-->62.500% (76.176%)\n",
      "TRAIN: 69 [1600/4038 (40%)]\tLoss: 1.088702, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.8823 (0.6887)\tACC-->62.500% (76.119%)\n",
      "TRAIN: 69 [3200/4038 (79%)]\tLoss: 0.882303, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.1388 (0.1388)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.011\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████████████▋                           | 70/100 [1:10:47<30:20, 60.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6934 (0.6934)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 70 [0/4038 (0%)]\tLoss: 0.693441, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.8610 (0.7328)\tACC-->68.750% (74.381%)\n",
      "TRAIN: 70 [1600/4038 (40%)]\tLoss: 0.861004, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.7061 (0.7277)\tACC-->75.000% (74.969%)\n",
      "TRAIN: 70 [3200/4038 (79%)]\tLoss: 0.706088, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.1650 (0.1650)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.713\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████████████▌                          | 71/100 [1:11:57<29:23, 60.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9152 (0.9152)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 71 [0/4038 (0%)]\tLoss: 0.915207, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.3742 (0.7144)\tACC-->81.250% (75.928%)\n",
      "TRAIN: 71 [1600/4038 (40%)]\tLoss: 0.374213, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->1.1410 (0.7149)\tACC-->62.500% (75.715%)\n",
      "TRAIN: 71 [3200/4038 (79%)]\tLoss: 1.141047, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.2333 (0.2333)\tACC-->87.500 (87.500)\n",
      " * Accuracy 89.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████████████▌                         | 72/100 [1:13:02<28:24, 60.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5135 (0.5135)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 72 [0/4038 (0%)]\tLoss: 0.513453, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.7836 (0.6913)\tACC-->75.000% (76.238%)\n",
      "TRAIN: 72 [1600/4038 (40%)]\tLoss: 0.783631, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.8246 (0.6777)\tACC-->68.750% (76.275%)\n",
      "TRAIN: 72 [3200/4038 (79%)]\tLoss: 0.824624, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.0803 (0.0803)\tACC-->100.000 (100.000)\n",
      " * Accuracy 91.854\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████████████▍                        | 73/100 [1:14:12<27:26, 60.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5106 (0.5106)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 73 [0/4038 (0%)]\tLoss: 0.510633, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.6133 (0.7032)\tACC-->75.000% (75.619%)\n",
      "TRAIN: 73 [1600/4038 (40%)]\tLoss: 0.613292, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.6274 (0.7054)\tACC-->87.500% (75.466%)\n",
      "TRAIN: 73 [3200/4038 (79%)]\tLoss: 0.627367, Accuracy: 14/16 (87.500%)\n",
      "VAL:   LOSS--> 0.1381 (0.1381)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.275\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████████████▎                       | 74/100 [1:15:25<26:29, 61.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.3037 (1.3037)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 74 [0/4038 (0%)]\tLoss: 1.303656, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.5665 (0.7128)\tACC-->81.250% (76.733%)\n",
      "TRAIN: 74 [1600/4038 (40%)]\tLoss: 0.566462, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.9108 (0.6902)\tACC-->62.500% (76.866%)\n",
      "TRAIN: 74 [3200/4038 (79%)]\tLoss: 0.910817, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.2146 (0.2146)\tACC-->87.500 (87.500)\n",
      " * Accuracy 91.433\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████████████▎                      | 75/100 [1:16:39<25:33, 61.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7171 (0.7171)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 75 [0/4038 (0%)]\tLoss: 0.717138, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.9238 (0.7159)\tACC-->56.250% (74.752%)\n",
      "TRAIN: 75 [1600/4038 (40%)]\tLoss: 0.923770, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.7187 (0.7198)\tACC-->68.750% (74.689%)\n",
      "TRAIN: 75 [3200/4038 (79%)]\tLoss: 0.718714, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.1547 (0.1547)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.820\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████████████████▏                     | 76/100 [1:17:53<24:35, 61.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.8327 (0.8327)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 76 [0/4038 (0%)]\tLoss: 0.832713, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.7543 (0.6964)\tACC-->75.000% (76.238%)\n",
      "TRAIN: 76 [1600/4038 (40%)]\tLoss: 0.754314, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.3451 (0.6909)\tACC-->93.750% (75.964%)\n",
      "TRAIN: 76 [3200/4038 (79%)]\tLoss: 0.345065, Accuracy: 15/16 (93.750%)\n",
      "VAL:   LOSS--> 0.6503 (0.6503)\tACC-->87.500 (87.500)\n",
      " * Accuracy 90.730\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|██████████████████████████████████████████████████████████████████████                     | 77/100 [1:19:06<23:37, 61.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3747 (0.3747)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 77 [0/4038 (0%)]\tLoss: 0.374687, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.8851 (0.7199)\tACC-->56.250% (75.309%)\n",
      "TRAIN: 77 [1600/4038 (40%)]\tLoss: 0.885097, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.2946 (0.6924)\tACC-->62.500% (76.182%)\n",
      "TRAIN: 77 [3200/4038 (79%)]\tLoss: 1.294573, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.2194 (0.2194)\tACC-->87.500 (87.500)\n",
      " * Accuracy 92.275\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████████████▉                    | 78/100 [1:20:18<22:39, 61.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7257 (0.7257)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 78 [0/4038 (0%)]\tLoss: 0.725652, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.5000 (0.7036)\tACC-->75.000% (76.733%)\n",
      "TRAIN: 78 [1600/4038 (40%)]\tLoss: 0.499954, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.3038 (0.6961)\tACC-->100.000% (76.430%)\n",
      "TRAIN: 78 [3200/4038 (79%)]\tLoss: 0.303821, Accuracy: 16/16 (100.000%)\n",
      "VAL:   LOSS--> 0.3622 (0.3622)\tACC-->87.500 (87.500)\n",
      " * Accuracy 92.978\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████████████▉                   | 79/100 [1:21:32<21:40, 61.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.3274 (0.3274)\tACC-->93.750% (93.750%)\n",
      "TRAIN: 79 [0/4038 (0%)]\tLoss: 0.327423, Accuracy: 15/16 (93.750%)\n",
      "TRAIN: LOSS-->0.3499 (0.7075)\tACC-->81.250% (75.124%)\n",
      "TRAIN: 79 [1600/4038 (40%)]\tLoss: 0.349935, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.6712 (0.6931)\tACC-->75.000% (76.182%)\n",
      "TRAIN: 79 [3200/4038 (79%)]\tLoss: 0.671182, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.1468 (0.1468)\tACC-->93.750 (93.750)\n",
      " * Accuracy 93.118\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████████████▊                  | 80/100 [1:22:44<20:41, 62.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7481 (0.7481)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 80 [0/4038 (0%)]\tLoss: 0.748129, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.3855 (0.6622)\tACC-->87.500% (77.661%)\n",
      "TRAIN: 80 [1600/4038 (40%)]\tLoss: 0.385487, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.7998 (0.6701)\tACC-->68.750% (77.674%)\n",
      "TRAIN: 80 [3200/4038 (79%)]\tLoss: 0.799824, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.0619 (0.0619)\tACC-->100.000 (100.000)\n",
      " * Accuracy 92.697\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████████████████████████████████████████████████████▋                 | 81/100 [1:23:55<19:41, 62.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0233 (1.0233)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 81 [0/4038 (0%)]\tLoss: 1.023329, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.6610 (0.6549)\tACC-->75.000% (77.475%)\n",
      "TRAIN: 81 [1600/4038 (40%)]\tLoss: 0.661044, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->1.0812 (0.6444)\tACC-->81.250% (77.519%)\n",
      "TRAIN: 81 [3200/4038 (79%)]\tLoss: 1.081223, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.2332 (0.2332)\tACC-->93.750 (93.750)\n",
      " * Accuracy 90.590\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|██████████████████████████████████████████████████████████████████████████▌                | 82/100 [1:25:10<18:41, 62.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.8408 (0.8408)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 82 [0/4038 (0%)]\tLoss: 0.840751, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.6038 (0.6386)\tACC-->81.250% (78.342%)\n",
      "TRAIN: 82 [1600/4038 (40%)]\tLoss: 0.603843, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.7820 (0.6663)\tACC-->68.750% (76.928%)\n",
      "TRAIN: 82 [3200/4038 (79%)]\tLoss: 0.782038, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.1734 (0.1734)\tACC-->93.750 (93.750)\n",
      " * Accuracy 91.152\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|███████████████████████████████████████████████████████████████████████████▌               | 83/100 [1:26:19<17:40, 62.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.8113 (0.8113)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 83 [0/4038 (0%)]\tLoss: 0.811318, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.0257 (0.6591)\tACC-->62.500% (76.671%)\n",
      "TRAIN: 83 [1600/4038 (40%)]\tLoss: 1.025682, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.2940 (0.6848)\tACC-->87.500% (76.057%)\n",
      "TRAIN: 83 [3200/4038 (79%)]\tLoss: 0.293965, Accuracy: 14/16 (87.500%)\n",
      "VAL:   LOSS--> 0.1590 (0.1590)\tACC-->93.750 (93.750)\n",
      " * Accuracy 94.101\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████████████▍              | 84/100 [1:27:26<16:39, 62.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7929 (0.7929)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 84 [0/4038 (0%)]\tLoss: 0.792860, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.5553 (0.6835)\tACC-->81.250% (76.609%)\n",
      "TRAIN: 84 [1600/4038 (40%)]\tLoss: 0.555331, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.5964 (0.6461)\tACC-->87.500% (77.736%)\n",
      "TRAIN: 84 [3200/4038 (79%)]\tLoss: 0.596407, Accuracy: 14/16 (87.500%)\n",
      "VAL:   LOSS--> 0.3114 (0.3114)\tACC-->93.750 (93.750)\n",
      " * Accuracy 92.978\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████████████▎             | 85/100 [1:28:36<15:38, 62.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6675 (0.6675)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 85 [0/4038 (0%)]\tLoss: 0.667501, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->1.3017 (0.6203)\tACC-->50.000% (78.280%)\n",
      "TRAIN: 85 [1600/4038 (40%)]\tLoss: 1.301717, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->0.5823 (0.6396)\tACC-->68.750% (77.114%)\n",
      "TRAIN: 85 [3200/4038 (79%)]\tLoss: 0.582263, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.1340 (0.1340)\tACC-->93.750 (93.750)\n",
      " * Accuracy 83.146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|██████████████████████████████████████████████████████████████████████████████▎            | 86/100 [1:29:48<14:37, 62.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5651 (0.5651)\tACC-->93.750% (93.750%)\n",
      "TRAIN: 86 [0/4038 (0%)]\tLoss: 0.565089, Accuracy: 15/16 (93.750%)\n",
      "TRAIN: LOSS-->0.8059 (0.6706)\tACC-->62.500% (76.856%)\n",
      "TRAIN: 86 [1600/4038 (40%)]\tLoss: 0.805868, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.5618 (0.6627)\tACC-->87.500% (77.208%)\n",
      "TRAIN: 86 [3200/4038 (79%)]\tLoss: 0.561824, Accuracy: 14/16 (87.500%)\n",
      "VAL:   LOSS--> 0.2125 (0.2125)\tACC-->93.750 (93.750)\n",
      " * Accuracy 93.539\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|███████████████████████████████████████████████████████████████████████████████▏           | 87/100 [1:30:59<13:35, 62.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5468 (0.5468)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 87 [0/4038 (0%)]\tLoss: 0.546774, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.7513 (0.6733)\tACC-->68.750% (76.733%)\n",
      "TRAIN: 87 [1600/4038 (40%)]\tLoss: 0.751299, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.4008 (0.6844)\tACC-->93.750% (75.995%)\n",
      "TRAIN: 87 [3200/4038 (79%)]\tLoss: 0.400795, Accuracy: 15/16 (93.750%)\n",
      "VAL:   LOSS--> 0.3158 (0.3158)\tACC-->81.250 (81.250)\n",
      " * Accuracy 91.994\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████████████           | 88/100 [1:32:09<12:34, 62.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7167 (0.7167)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 88 [0/4038 (0%)]\tLoss: 0.716657, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.3774 (0.6310)\tACC-->81.250% (77.290%)\n",
      "TRAIN: 88 [1600/4038 (40%)]\tLoss: 0.377403, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.7491 (0.6356)\tACC-->81.250% (77.892%)\n",
      "TRAIN: 88 [3200/4038 (79%)]\tLoss: 0.749133, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.1020 (0.1020)\tACC-->93.750 (93.750)\n",
      " * Accuracy 91.573\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████████████████████████████████████████████████████████████████████████████▉          | 89/100 [1:33:20<11:32, 62.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4493 (0.4493)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 89 [0/4038 (0%)]\tLoss: 0.449253, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.6366 (0.6577)\tACC-->81.250% (76.671%)\n",
      "TRAIN: 89 [1600/4038 (40%)]\tLoss: 0.636633, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->1.3711 (0.6720)\tACC-->62.500% (76.493%)\n",
      "TRAIN: 89 [3200/4038 (79%)]\tLoss: 1.371077, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.2903 (0.2903)\tACC-->87.500 (87.500)\n",
      " * Accuracy 93.961\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████████████▉         | 90/100 [1:34:26<10:29, 62.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5621 (0.5621)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 90 [0/4038 (0%)]\tLoss: 0.562145, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.8365 (0.6487)\tACC-->75.000% (76.547%)\n",
      "TRAIN: 90 [1600/4038 (40%)]\tLoss: 0.836497, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.4116 (0.6749)\tACC-->75.000% (75.560%)\n",
      "TRAIN: 90 [3200/4038 (79%)]\tLoss: 0.411629, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.3246 (0.3246)\tACC-->81.250 (81.250)\n",
      " * Accuracy 93.539\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████████████▊        | 91/100 [1:35:38<09:27, 63.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7575 (0.7575)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 91 [0/4038 (0%)]\tLoss: 0.757455, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.5819 (0.7026)\tACC-->68.750% (76.238%)\n",
      "TRAIN: 91 [1600/4038 (40%)]\tLoss: 0.581884, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.8096 (0.6779)\tACC-->68.750% (76.928%)\n",
      "TRAIN: 91 [3200/4038 (79%)]\tLoss: 0.809601, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.2012 (0.2012)\tACC-->87.500 (87.500)\n",
      " * Accuracy 88.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████████████▋       | 92/100 [1:36:42<08:24, 63.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5633 (0.5633)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 92 [0/4038 (0%)]\tLoss: 0.563285, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.3339 (0.6568)\tACC-->87.500% (77.599%)\n",
      "TRAIN: 92 [1600/4038 (40%)]\tLoss: 0.333905, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.7591 (0.6283)\tACC-->81.250% (78.265%)\n",
      "TRAIN: 92 [3200/4038 (79%)]\tLoss: 0.759120, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.1429 (0.1429)\tACC-->93.750 (93.750)\n",
      " * Accuracy 91.854\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|████████████████████████████████████████████████████████████████████████████████████▋      | 93/100 [1:37:45<07:21, 63.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4180 (0.4180)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 93 [0/4038 (0%)]\tLoss: 0.418042, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->0.3987 (0.6740)\tACC-->81.250% (78.156%)\n",
      "TRAIN: 93 [1600/4038 (40%)]\tLoss: 0.398662, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.5034 (0.6598)\tACC-->81.250% (77.830%)\n",
      "TRAIN: 93 [3200/4038 (79%)]\tLoss: 0.503398, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.1415 (0.1415)\tACC-->93.750 (93.750)\n",
      " * Accuracy 92.275\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████████████████████████████████████████████████████████████████████████████████▌     | 94/100 [1:38:52<06:18, 63.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6699 (0.6699)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 94 [0/4038 (0%)]\tLoss: 0.669890, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.2341 (0.6309)\tACC-->93.750% (78.094%)\n",
      "TRAIN: 94 [1600/4038 (40%)]\tLoss: 0.234079, Accuracy: 15/16 (93.750%)\n",
      "TRAIN: LOSS-->0.7528 (0.6409)\tACC-->68.750% (78.109%)\n",
      "TRAIN: 94 [3200/4038 (79%)]\tLoss: 0.752822, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.2187 (0.2187)\tACC-->93.750 (93.750)\n",
      " * Accuracy 93.258\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|██████████████████████████████████████████████████████████████████████████████████████▍    | 95/100 [1:40:02<05:15, 63.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.2217 (0.2217)\tACC-->93.750% (93.750%)\n",
      "TRAIN: 95 [0/4038 (0%)]\tLoss: 0.221700, Accuracy: 15/16 (93.750%)\n",
      "TRAIN: LOSS-->0.6934 (0.6262)\tACC-->68.750% (77.042%)\n",
      "TRAIN: 95 [1600/4038 (40%)]\tLoss: 0.693370, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.9105 (0.6696)\tACC-->62.500% (76.182%)\n",
      "TRAIN: 95 [3200/4038 (79%)]\tLoss: 0.910518, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.1587 (0.1587)\tACC-->93.750 (93.750)\n",
      " * Accuracy 91.994\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|███████████████████████████████████████████████████████████████████████████████████████▎   | 96/100 [1:41:06<04:12, 63.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6996 (0.6996)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 96 [0/4038 (0%)]\tLoss: 0.699560, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.4050 (0.6129)\tACC-->93.750% (79.455%)\n",
      "TRAIN: 96 [1600/4038 (40%)]\tLoss: 0.404974, Accuracy: 15/16 (93.750%)\n",
      "TRAIN: LOSS-->0.5373 (0.6297)\tACC-->81.250% (78.420%)\n",
      "TRAIN: 96 [3200/4038 (79%)]\tLoss: 0.537280, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.3561 (0.3561)\tACC-->87.500 (87.500)\n",
      " * Accuracy 91.994\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|████████████████████████████████████████████████████████████████████████████████████████▎  | 97/100 [1:42:08<03:09, 63.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0752 (1.0752)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 97 [0/4038 (0%)]\tLoss: 1.075181, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.4874 (0.6450)\tACC-->81.250% (77.537%)\n",
      "TRAIN: 97 [1600/4038 (40%)]\tLoss: 0.487364, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.5338 (0.6285)\tACC-->75.000% (77.923%)\n",
      "TRAIN: 97 [3200/4038 (79%)]\tLoss: 0.533838, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.0666 (0.0666)\tACC-->100.000 (100.000)\n",
      " * Accuracy 93.680\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████▏ | 98/100 [1:43:10<02:06, 63.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5213 (0.5213)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 98 [0/4038 (0%)]\tLoss: 0.521296, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.9502 (0.6697)\tACC-->56.250% (78.651%)\n",
      "TRAIN: 98 [1600/4038 (40%)]\tLoss: 0.950212, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.4948 (0.6406)\tACC-->81.250% (78.700%)\n",
      "TRAIN: 98 [3200/4038 (79%)]\tLoss: 0.494757, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.2865 (0.2865)\tACC-->87.500 (87.500)\n",
      " * Accuracy 92.837\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████ | 99/100 [1:44:14<01:03, 63.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5363 (0.5363)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 99 [0/4038 (0%)]\tLoss: 0.536270, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.4761 (0.6571)\tACC-->75.000% (76.547%)\n",
      "TRAIN: 99 [1600/4038 (40%)]\tLoss: 0.476098, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.5330 (0.6535)\tACC-->81.250% (76.897%)\n",
      "TRAIN: 99 [3200/4038 (79%)]\tLoss: 0.533005, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.1156 (0.1156)\tACC-->100.000 (100.000)\n",
      " * Accuracy 94.101\n",
      "EARLY STOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [1:45:24<00:00, 63.25s/it]\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "sample_submission.columns = ['file', 'species']\n",
    "# sample_submission['category_id'] = 0\n",
    "sample_submission.head(3)\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    print (\"MODEL: {}\".format( str(type(model).__name__)))\n",
    "    for epoch in tqdm(range(0, 100)):        \n",
    "        train(t_loader, model, epoch, optimizer)\n",
    "        val_loss, val_accuracy= validate(v_loader, model, epoch)\n",
    "        if float(val_accuracy) > float(90.0):            \n",
    "            print (\"EARLY STOP\")\n",
    "            df_pred=testModel(test_data_dir,model)\n",
    "            df_pred.to_csv(str(type(model).__name__) + '_' + str(val_accuracy) + '_' + \n",
    "                           str(epoch) + \"_sub.csv\", columns=('file', 'species'), index=None)         \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example submission on the Kaggle seedlings DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), str(type(model).__name__) + '_' + str(val_accuracy) + '_.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, participants will be asked to provide the following classification rates:\n",
    "\n",
    "-- TP (True Positive, which is the number of OP people correctly identified),\n",
    "\n",
    "-- FP (False Positive, which is the number of CT people incorrectly identified),\n",
    "\n",
    "-- TN (True Negative, which is the number of CT people correctly identified),\n",
    "\n",
    "-- FN (False Negative, which is the number of OP people incorrectly identified),\n",
    "\n",
    "-- Sn (True positive rate or sensitivity) as Sn = TP/(TP + FN),\n",
    "\n",
    "-- Sp (Specificity or True Negative Rate) as Sp = TN/(FP + TN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
