{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tel-Aviv Deep Learning Boot-camp: 12 Applied Deep Learning Labs\n",
    "\n",
    "## Lab 0: Plant Seedlings Classification (PyTorch): The most basic lab :)  \n",
    "\n",
    "<img src=\"../assets/seedlings.png\" align=\"center\">\n",
    "\n",
    "### Instructors:\n",
    "\n",
    "- Shlomo Kashani: shlomo@bayesian.io ,\n",
    "- Nathaniel Shimoni nathaniel.shimoni@grid4c.com \n",
    "\n",
    "<img src=\"../assets/pt.jpg\" width=\"35%\" align=\"center\">\n",
    "\n",
    "## Progress\n",
    "\n",
    "- [x] PyTorch DataSet\n",
    "- [x] PyTorch DataLoader\n",
    "- [x] Augmentations\n",
    "- [x] Simple CNN\n",
    "- [x] Training + train test split\n",
    "- [x] TensorBoard Support from PyTorch\n",
    "- [x] Accuray and Log Loss\n",
    "- [x] Tqdm progress\n",
    "- [x] Persisting the model\n",
    "- [x] Testing on a test set\n",
    "\n",
    "\n",
    "\n",
    "### Links:\n",
    "\n",
    "- https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/ \n",
    "- Git: https://github.com/bayesianio/applied-dl-2018\n",
    "- Full info: https://www.evernote.com/shard/s341/sh/3855640e-2b0b-42e5-b5b9-00216d02ac9a/b47968226e49a81ee813901cd41d3924\n",
    "\n",
    "### Date and Location: \n",
    "- July 2018\n",
    "\n",
    "\n",
    "### Requirements:\n",
    "- Python 3.5, CUDA 9, cuDNN 7, PyTorch 2.0 or above, Keras 2 or above\n",
    "\n",
    "#### For Windows 10 and Windows Server 2016, CUDA 9\n",
    "`conda install -c peterjc123 pytorch cuda90`\n",
    "\n",
    "\n",
    "### Data\n",
    "- Download: https://www.kaggle.com/c/plant-seedlings-classification\n",
    "\n",
    "- Please make sure you have already set up a Pytorch tree structure of your dataset:\n",
    "- `data_dir= '/home/data/bone/train/' `\n",
    "\n",
    "```\n",
    "    data_dir= '/home/data/bone/train/\n",
    "    \n",
    "    ├── valid\n",
    "    │   └── Type_1\n",
    "        ├── Type_2\n",
    "        └── Type_3\n",
    "    └── train\n",
    "        ├── Type_1\n",
    "        ├── Type_2\n",
    "        └── Type_3\n",
    "```\n",
    "\n",
    "### PyTorch Datasets\n",
    "\n",
    "To create a dataset, we subclass Dataset and define a constructor, a `__len__` method, and a `__getitem__` method. \n",
    "Here is full example:\n",
    "\n",
    "```python\n",
    "class BoneDataset(Dataset):\n",
    "    def __init__(self, labels, root_dir, subset=False, transform=None):\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels.iloc[idx, 0] # file name\n",
    "        fullname = join(self.root_dir, img_name)\n",
    "        image = Image.open(fullname).convert('RGB')\n",
    "        labels = self.labels.iloc[idx, 2] # category_id\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n",
    "```\n",
    "\n",
    "### The PyTorch DataLoader Class¶\n",
    "- Will load our BoneDataset\n",
    "- Can be regarded as a list (or iterator, technically).\n",
    "- Each time it is invoked will provide a minibatch of (img, label) pairs.\n",
    "\n",
    "\n",
    "### Training with TensorBoard\n",
    "\n",
    "With the aid of [Crayon](https://github.com/torrvision/crayon),\n",
    "we can access the visualisation power of TensorBoard for any \n",
    "deep learning framework.\n",
    "\n",
    "To use the TensorBoard, install Crayon (https://github.com/torrvision/crayon)\n",
    "and set `use_tensorboard = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "42dcf0c0-28f0-4386-9ee3-367f3606aa30",
    "_uuid": "33595673f3f93faf28ed0ac10f0a7c0e59a9c0ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.6.2 |Anaconda custom (64-bit)| (default, Sep 19 2017, 08:03:39) [MSC v.1900 64 bit (AMD64)]\n",
      "__pyTorch VERSION: 0.2.1+a4fc05a\n",
      "__CUDA VERSION\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2017 NVIDIA Corporation\n",
      "Built on Fri_Sep__1_21:08:32_Central_Daylight_Time_2017\n",
      "Cuda compilation tools, release 9.0, V9.0.176\n",
      "__CUDNN VERSION: None\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n",
      "Available devices  1\n",
      "Current cuda device  0\n",
      "USE CUDA=True\n"
     ]
    }
   ],
   "source": [
    "%reset -f \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from shutil import copyfile\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as func\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import random \n",
    "\n",
    "\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "# call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "print(\"USE CUDA=\" + str (use_cuda))\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "manualSeed = None\n",
    "def fixSeed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "if manualSeed is None:\n",
    "        manualSeed = 999\n",
    "fixSeed(manualSeed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "579bc4ea-49c2-4413-a4bf-57472a155db4",
    "_uuid": "ab87c9fc87053c27d96e4765be8a942e91bf79bd"
   },
   "source": [
    "### Define Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "796ac7f9-d66a-4856-acba-b1be8f4960b6",
    "_uuid": "e32251e2e44d9bf3b14af6153643b36110cb17ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black-grass/0050f38b3.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black-grass/0183fdf68.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black-grass/0260cffa8.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black-grass/05eedce4d.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black-grass/075d004bc.png</td>\n",
       "      <td>Black-grass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file     category  category_id\n",
       "0  Black-grass/0050f38b3.png  Black-grass            0\n",
       "1  Black-grass/0183fdf68.png  Black-grass            0\n",
       "2  Black-grass/0260cffa8.png  Black-grass            0\n",
       "3  Black-grass/05eedce4d.png  Black-grass            0\n",
       "4  Black-grass/075d004bc.png  Black-grass            0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BoneDataset(Dataset):\n",
    "    def __init__(self, labels, root_dir, subset=False, transform=None):\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels.iloc[idx, 0] # file name\n",
    "        fullname = join(self.root_dir, img_name)\n",
    "        image = Image.open(fullname).convert('RGB')\n",
    "        labels = self.labels.iloc[idx, 2] # category_id\n",
    "#         print (labels)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n",
    "    \n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "data_dir= 'd:/db/data/bone/train/'\n",
    "data_dir= 'd:/db/data/cat-dog/train/'\n",
    "data_dir= 'd:/db/data/seedings/train/'\n",
    "\n",
    "def find_classes(fullDir):\n",
    "    classes = [d for d in os.listdir(fullDir) if os.path.isdir(os.path.join(fullDir, d))]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    num_to_class = dict(zip(range(len(classes)), classes))\n",
    "    \n",
    "    train = []\n",
    "    for index, label in enumerate(classes):\n",
    "        path = fullDir + label + '/'\n",
    "        for file in listdir(path):\n",
    "            train.append(['{}/{}'.format(label, file), label, index])\n",
    "    \n",
    "    df = pd.DataFrame(train, columns=['file', 'category', 'category_id',]) \n",
    "\n",
    "    return classes, class_to_idx, num_to_class, df\n",
    "\n",
    "classes, class_to_idx, num_to_class, df =find_classes (data_dir )\n",
    "\n",
    "\n",
    "# class_to_idx\n",
    "# num_to_class\n",
    "df.head(5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation \n",
    "- Many of the code snippts here were adapted from various github repos.\n",
    "- If you dont need augementation, just skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "from torchvision.transforms import *\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import numbers\n",
    "import math\n",
    "import torch\n",
    "import torch\n",
    "import random\n",
    "import PIL.ImageEnhance as ie\n",
    "import PIL.Image as im\n",
    "\n",
    "# adapted from https://github.com/kuangliu/pytorch-retinanet/blob/master/transform.py\n",
    "# https://github.com/mratsim/Amazon-Forest-Computer-Vision/blob/master/src/p_data_augmentation.py\n",
    "\n",
    "normalize_img = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def draw(img, boxes):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for box in boxes:\n",
    "        draw.rectangle(list(box), outline='red')\n",
    "    img.show()\n",
    "\n",
    "\n",
    "class Stack(object):\n",
    "\n",
    "    def __init__(self, roll=False):\n",
    "        self.roll = roll\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        if img_group[0].mode == 'L':\n",
    "            return np.concatenate([np.expand_dims(x, 2) for x in img_group], axis=2)\n",
    "        elif img_group[0].mode == 'RGB':\n",
    "            if self.roll:\n",
    "                return np.concatenate([np.array(x)[:, :, ::-1] for x in img_group], axis=2)\n",
    "            else:\n",
    "                return np.concatenate(img_group, axis=2)\n",
    "\n",
    "\n",
    "class ToTorchFormatTensor(object):\n",
    "    \"\"\" Converts a PIL.Image (RGB) or numpy.ndarray (H x W x C) in the range [0, 255]\n",
    "    to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \"\"\"\n",
    "    def __init__(self, div=True):\n",
    "        self.div = div\n",
    "\n",
    "    def __call__(self, pic):\n",
    "        if isinstance(pic, np.ndarray):\n",
    "            # handle numpy array\n",
    "            img = torch.from_numpy(pic).permute(2, 0, 1).contiguous()\n",
    "        else:\n",
    "            # handle PIL Image\n",
    "            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
    "            img = img.view(pic.size[1], pic.size[0], len(pic.mode))\n",
    "            # put it from HWC to CHW format\n",
    "            # yikes, this transpose takes 80% of the loading time/CPU\n",
    "            img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "        return img.float().div(255) if self.div else img.float()\n",
    "\n",
    "\n",
    "class IdentityTransform(object):\n",
    "\n",
    "    def __call__(self, data):\n",
    "        return data\n",
    "\n",
    "class RandomErasing(object):\n",
    "    def __init__(self, EPSILON = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n",
    "        self.EPSILON = EPSILON\n",
    "        self.mean = mean\n",
    "        self.sl = sl\n",
    "        self.sh = sh\n",
    "        self.r1 = r1\n",
    "       \n",
    "    def __call__(self, img):\n",
    "\n",
    "        if random.uniform(0, 1) > self.EPSILON:\n",
    "            return img\n",
    "\n",
    "        for attempt in range(100):\n",
    "            area = img.size()[1] * img.size()[2]\n",
    "       \n",
    "            target_area = random.uniform(self.sl, self.sh) * area\n",
    "            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n",
    "\n",
    "            h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "            w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "            if w <= img.size()[2] and h <= img.size()[1]:\n",
    "                x1 = random.randint(0, img.size()[1] - h)\n",
    "                y1 = random.randint(0, img.size()[2] - w)\n",
    "                if img.size()[0] == 3:\n",
    "                    #img[0, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
    "                    #img[1, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
    "                    #img[2, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n",
    "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
    "                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n",
    "                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n",
    "                    #img[:, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(3, h, w))\n",
    "                else:\n",
    "                    img[0, x1:x1+h, y1:y1+w] = self.mean[1]\n",
    "                    # img[0, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(1, h, w))\n",
    "                return img\n",
    "\n",
    "        return img\n",
    "\n",
    "def random_crop(img, boxes):\n",
    "    '''Crop the given PIL image to a random size and aspect ratio.\n",
    "    A crop of random size of (0.08 to 1.0) of the original size and a random\n",
    "    aspect ratio of 3/4 to 4/3 of the original aspect ratio is made.\n",
    "    Args:\n",
    "      img: (PIL.Image) image to be cropped.\n",
    "      boxes: (tensor) object boxes, sized [#ojb,4].\n",
    "    Returns:\n",
    "      img: (PIL.Image) randomly cropped image.\n",
    "      boxes: (tensor) randomly cropped boxes.\n",
    "    '''\n",
    "    success = False\n",
    "    for attempt in range(10):\n",
    "        area = img.size[0] * img.size[1]\n",
    "        target_area = random.uniform(0.56, 1.0) * area\n",
    "        aspect_ratio = random.uniform(3. / 4, 4. / 3)\n",
    "\n",
    "        w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "        h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            w, h = h, w\n",
    "\n",
    "        if w <= img.size[0] and h <= img.size[1]:\n",
    "            x = random.randint(0, img.size[0] - w)\n",
    "            y = random.randint(0, img.size[1] - h)\n",
    "            success = True\n",
    "            break\n",
    "\n",
    "    # Fallback\n",
    "    if not success:\n",
    "        w = h = min(img.size[0], img.size[1])\n",
    "        x = (img.size[0] - w) // 2\n",
    "        y = (img.size[1] - h) // 2\n",
    "\n",
    "    img = img.crop((x, y, x+w, y+h))\n",
    "    boxes -= torch.Tensor([x,y,x,y])\n",
    "    boxes[:,0::2].clamp_(min=0, max=w-1)\n",
    "    boxes[:,1::2].clamp_(min=0, max=h-1)\n",
    "    return img, boxes\n",
    "\n",
    "\n",
    "class Lighting(object):\n",
    "    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n",
    "\n",
    "    def __init__(self, alphastd, eigval, eigvec):\n",
    "        self.alphastd = alphastd\n",
    "        self.eigval = eigval\n",
    "        self.eigvec = eigvec\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.alphastd == 0:\n",
    "            return img\n",
    "\n",
    "        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n",
    "        rgb = self.eigvec.type_as(img).clone() \\\n",
    "            .mul(alpha.view(1, 3).expand(3, 3)) \\\n",
    "            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n",
    "            .sum(1).squeeze()\n",
    "\n",
    "        return img.add(rgb.view(3, 1, 1).expand_as(img))\n",
    "\n",
    "\n",
    "class Grayscale(object):\n",
    "    def __call__(self, img):\n",
    "        gs = img.clone()\n",
    "        gs[0].mul_(0.299).add_(0.587, gs[1]).add_(0.114, gs[2])\n",
    "        gs[1].copy_(gs[0])\n",
    "        gs[2].copy_(gs[0])\n",
    "        return gs\n",
    "\n",
    "\n",
    "class Saturation(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = Grayscale()(img)\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class Brightness(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = img.new().resize_as_(img).zero_()\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class Contrast(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = Grayscale()(img)\n",
    "        gs.fill_(gs.mean())\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class RandomOrder(object):\n",
    "    \"\"\" Composes several transforms together in random order.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.transforms is None:\n",
    "            return img\n",
    "        order = torch.randperm(len(self.transforms))\n",
    "        for i in order:\n",
    "            img = self.transforms[i](img)\n",
    "        return img\n",
    "\n",
    "\n",
    "class ColorJitter(RandomOrder):\n",
    "    def __init__(self, brightness=0.4, contrast=0.4, saturation=0.4):\n",
    "        self.transforms = []\n",
    "        if brightness != 0:\n",
    "            self.transforms.append(Brightness(brightness))\n",
    "        if contrast != 0:\n",
    "            self.transforms.append(Contrast(contrast))\n",
    "        if saturation != 0:\n",
    "            self.transforms.append(Saturation(saturation))\n",
    "\n",
    "\n",
    "class RandomFlip(object):\n",
    "    \"\"\"Randomly flips the given PIL.Image with a probability of 0.25 horizontal,\n",
    "                                                                0.25 vertical,\n",
    "                                                                0.5 as is\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, img):\n",
    "        dispatcher = {\n",
    "            0: img,\n",
    "            1: img,\n",
    "            2: img.transpose(im.FLIP_LEFT_RIGHT),\n",
    "            3: img.transpose(im.FLIP_TOP_BOTTOM)\n",
    "        }\n",
    "\n",
    "        return dispatcher[random.randint(0, 3)]  # randint is inclusive\n",
    "\n",
    "\n",
    "class RandomRotate(object):\n",
    "    \"\"\"Randomly rotate the given PIL.Image with a probability of 1/6 90°,\n",
    "                                                                 1/6 180°,\n",
    "                                                                 1/6 270°,\n",
    "                                                                 1/2 as is\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, img):\n",
    "        dispatcher = {\n",
    "            0: img,\n",
    "            1: img,\n",
    "            2: img,\n",
    "            3: img.transpose(im.ROTATE_90),\n",
    "            4: img.transpose(im.ROTATE_180),\n",
    "            5: img.transpose(im.ROTATE_270)\n",
    "        }\n",
    "\n",
    "        return dispatcher[random.randint(0, 5)]  # randint is inclusive\n",
    "\n",
    "\n",
    "class PILColorBalance(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Color(img).enhance(alpha)\n",
    "\n",
    "\n",
    "class PILContrast(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Contrast(img).enhance(alpha)\n",
    "\n",
    "\n",
    "class PILBrightness(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Brightness(img).enhance(alpha)\n",
    "\n",
    "\n",
    "class PILSharpness(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Sharpness(img).enhance(alpha)\n",
    "\n",
    "\n",
    "# Check ImageEnhancer effect: https://www.youtube.com/watch?v=_7iDTpTop04\n",
    "# Not documented but all enhancements can go beyond 1.0 to 2\n",
    "# Image must be RGB\n",
    "# Use Pillow-SIMD because Pillow is too slow\n",
    "class PowerPIL(RandomOrder):\n",
    "    def __init__(self, rotate=True,\n",
    "                 flip=True,\n",
    "                 colorbalance=0.4,\n",
    "                 contrast=0.4,\n",
    "                 brightness=0.4,\n",
    "                 sharpness=0.4):\n",
    "        self.transforms = []\n",
    "        if rotate:\n",
    "            self.transforms.append(RandomRotate())\n",
    "        if flip:\n",
    "            self.transforms.append(RandomFlip())\n",
    "        if brightness != 0:\n",
    "            self.transforms.append(PILBrightness(brightness))\n",
    "        if contrast != 0:\n",
    "            self.transforms.append(PILContrast(contrast))\n",
    "        if colorbalance != 0:\n",
    "            self.transforms.append(PILColorBalance(colorbalance))\n",
    "        if sharpness != 0:\n",
    "            self.transforms.append(PILSharpness(sharpness))\n",
    "\n",
    "def default_loader(input_path):\n",
    "    input_image = (Image.open(input_path)).convert('RGB')\n",
    "    return input_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bc8a9969-280a-4ec8-850b-25aed1ee38d6",
    "_uuid": "0163fcd2a2ea5a4e93bc87f47a96f404bcad6a83"
   },
   "source": [
    "## Setup transforms, datasets, and dataloaders\n",
    "\n",
    "- Data loaders spit out data from a dataset in batches. This is what you actually feed the neural network during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "f94cb9fa-e76a-46d5-a363-8856b45c59e1",
    "_uuid": "fe82da4f8b1501203d12027200d1f8d2209f0057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 4038, 'valid': 712}\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "\n",
    "normalize_img = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.RandomSizedCrop(image_size),\n",
    "    PowerPIL(),\n",
    "    transforms.ToTensor(),\n",
    "#     normalize_img,\n",
    "    RandomErasing()\n",
    "])\n",
    "\n",
    "## Normalization only for validation and test\n",
    "valid_trans = transforms.Compose([\n",
    "    transforms.Scale(256),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "#     normalize_img\n",
    "])\n",
    "\n",
    "batch_size = 16\n",
    "train_data = df.sample(frac=0.85)\n",
    "valid_data = df[~df['file'].isin(train_data['file'])]\n",
    "\n",
    "train_set = BoneDataset(train_data, data_dir, transform = train_trans)\n",
    "valid_set = BoneDataset(valid_data, data_dir, transform = valid_trans)\n",
    "        \n",
    "\n",
    "t_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "v_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "# test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(t_loader.dataset), \n",
    "    'valid': len(v_loader.dataset)\n",
    "}\n",
    "\n",
    "print (dataset_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the DataLoader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0: \n",
      "i=1: \n",
      "i=2: \n",
      "i=3: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAABvCAYAAACjFLT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4e8+evp8V/YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1994717b748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagesToShow=4\n",
    "\n",
    "def flaotTensorToImage(img, mean=0, std=1):\n",
    "        \"\"\"convert a tensor to an image\"\"\"\n",
    "        img = np.transpose(img.numpy(), (1, 2, 0))\n",
    "        img = (img*std+ mean)*255\n",
    "        img = img.astype(np.uint8)    \n",
    "        return img    \n",
    "\n",
    "for i, data in enumerate(t_loader, 0):\n",
    "    print('i=%d: '%(i))            \n",
    "    images, labels = data            \n",
    "    num = len(images)\n",
    "    \n",
    "    ax = plt.subplot(1, imagesToShow, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    for n in range(num):\n",
    "        image=images[n]\n",
    "        label=labels[n]\n",
    "        plt.imshow (flaotTensorToImage(image))\n",
    "        \n",
    "    if i==imagesToShow-1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d966c8a9-d189-4b76-8def-6180f9498154",
    "_uuid": "fde155bdd9ce81e2598146c263cedfa65eaba806"
   },
   "source": [
    "## Define the model\n",
    "- A simple CNN with great performance (95% accuracy) \n",
    "- In PyTorch, a model is defined by a subclass of nn.Module. It has two methods:\n",
    "\n",
    "`__init__:` constructor. Create layers here. Note that we don't define the connections between layers in this function.\n",
    "\n",
    "`forward(x):` forward function. Receives an input variable x. Returns a output variable. Note that we actually connect the layers here dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "f2eb7b14-c63b-4fdf-8370-baabd48a9943",
    "_uuid": "29184efaeb75c7105b9f144550b68814c577534a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet (\n",
      "  (avgpool): AdaptiveAvgPool2d (output_size=1)\n",
      "  (cnn1): ConvCNN (\n",
      "    (math): Sequential (\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(2, 2))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (2): LeakyReLU (0.01)\n",
      "      (3): MaxPool2d (size=(4, 4), stride=(4, 4), dilation=(1, 1))\n",
      "    )\n",
      "    (avgpool): AvgPool2d (size=4, stride=4, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "  )\n",
      "  (cnn2): ConvCNN (\n",
      "    (math): Sequential (\n",
      "      (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (2): LeakyReLU (0.01)\n",
      "      (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    )\n",
      "    (avgpool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "  )\n",
      "  (cnn3): ConvCNN (\n",
      "    (math): Sequential (\n",
      "      (0): Conv2d(64, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (2): LeakyReLU (0.01)\n",
      "      (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    )\n",
      "    (avgpool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "  )\n",
      "  (res1): ConvRes (\n",
      "    (math): Sequential (\n",
      "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (1): Dropout (p = 0.3)\n",
      "      (2): Conv2d(512, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "      (3): PReLU (1)\n",
      "    )\n",
      "  )\n",
      "  (features): Sequential (\n",
      "    (0): ConvCNN (\n",
      "      (math): Sequential (\n",
      "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(2, 2))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (2): LeakyReLU (0.01)\n",
      "        (3): MaxPool2d (size=(4, 4), stride=(4, 4), dilation=(1, 1))\n",
      "      )\n",
      "      (avgpool): AvgPool2d (size=4, stride=4, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (1): Dropout (p = 0.3)\n",
      "    (2): ConvCNN (\n",
      "      (math): Sequential (\n",
      "        (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (2): LeakyReLU (0.01)\n",
      "        (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      )\n",
      "      (avgpool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (3): ConvCNN (\n",
      "      (math): Sequential (\n",
      "        (0): Conv2d(64, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (2): LeakyReLU (0.01)\n",
      "        (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      )\n",
      "      (avgpool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (4): ConvRes (\n",
      "      (math): Sequential (\n",
      "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (1): Dropout (p = 0.3)\n",
      "        (2): Conv2d(512, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "        (3): PReLU (1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential (\n",
      "    (0): Linear (2304 -> 12)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import math \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.30)\n",
    "relu=torch.nn.LeakyReLU()\n",
    "pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "class ConvRes(nn.Module):\n",
    "    def __init__(self,insize, outsize):\n",
    "        super(ConvRes, self).__init__()\n",
    "        drate = .3\n",
    "        self.math = nn.Sequential(\n",
    "                 nn.BatchNorm2d(insize),\n",
    "                 nn.Dropout(drate),\n",
    "                 torch.nn.Conv2d(insize, outsize, kernel_size=2,padding=2),\n",
    "                 nn.PReLU(),\n",
    "                )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.math(x) \n",
    "\n",
    "class ConvCNN(nn.Module):\n",
    "    def __init__(self,insize, outsize, kernel_size=7, padding=2, pool=2, avg=True):\n",
    "        super(ConvCNN, self).__init__()\n",
    "        self.avg=avg\n",
    "        self.math = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(insize, outsize, kernel_size=kernel_size,padding=padding),\n",
    "            torch.nn.BatchNorm2d(outsize),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d(pool,pool),\n",
    "        )\n",
    "        self.avgpool=torch.nn.AvgPool2d(pool,pool)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.math(x)\n",
    "        if self.avg is True:\n",
    "            x=self.avgpool(x)\n",
    "        return x   \n",
    "        \n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()        \n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.cnn1 = ConvCNN (3,64,  kernel_size=7, pool=4, avg=False)\n",
    "        self.cnn2 = ConvCNN (64,64, kernel_size=5, pool=2, avg=True)\n",
    "        self.cnn3 = ConvCNN (64,512, kernel_size=5, pool=2, avg=True)\n",
    "        \n",
    "        self.res1 = ConvRes (512,64)\n",
    "        \n",
    "        self.features = nn.Sequential( \n",
    "            self.cnn1,dropout,          \n",
    "            self.cnn2,\n",
    "            self.cnn3,\n",
    "            self.res1,\n",
    "        )        \n",
    "        \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            nn.Linear(2304, len(classes)),             \n",
    "        )\n",
    "#         self.sig=nn.Sigmoid()        \n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.features(x) \n",
    "        x = x.view(x.size(0), -1)        \n",
    "#         print (x.data.shape)\n",
    "        x = self.classifier(x)                \n",
    "#         x = self.sig(x)\n",
    "        return x        \n",
    "\n",
    "model = SimpleNet()\n",
    "# model = senetXX_generic(1, 3, 16)\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 0.00005 * 2 * 2)\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics and Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime \n",
    "try:\n",
    "    from pycrayon import CrayonClient\n",
    "except ImportError:\n",
    "    CrayonClient = None\n",
    "\n",
    "# tensorboad\n",
    "use_tensorboard = True\n",
    "# use_tensorboard = True and CrayonClient is not None\n",
    "\n",
    "if use_tensorboard == True:\n",
    "    cc = CrayonClient(hostname='http://192.168.1.2') # point to where you installed Crayon\n",
    "#     cc.remove_all_experiments()\n",
    "    \n",
    "model_name = (type(model).__name__)\n",
    "exp_name = datetime.datetime.now().strftime(model_name + '_' + 'bone' + '_%Y-%m-%d_%H-%M-%S')\n",
    "if use_tensorboard == True:\n",
    "    exp = cc.create_experiment(exp_name)    \n",
    "    \n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy2(y_pred, y_actual, topk=(1, )):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = y_actual.size(0)\n",
    "\n",
    "    _, pred = y_pred.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(y_actual.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0cd8c571-5d93-42b6-9ef0-9c16b6d43ef7",
    "_uuid": "1257d2cc10e64019a8ca94c814d4e179a45e04cd"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2cd5d63-c765-476a-9258-0152d8a06360",
    "_uuid": "d5ecfa57978ed8afd52e1551f6f5688ce9e16a5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "\n",
    "def train(train_loader, model, epoch, optimizer):\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "        criterion.cuda()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "   \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for batch_idx, (images, target) in enumerate(train_loader): \n",
    "        correct = 0\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            images, target = images.cuda(), target.cuda()\n",
    "            images, target = Variable(images), Variable(target)\n",
    "        # compute y_pred\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec1 = accuracy2(y_pred.data, target.data, topk=(1, 1))\n",
    "        losses.update(loss.data[0], images.size(0))\n",
    "        acc.update(prec1[0], images.size(0))\n",
    "        \n",
    "        pred = y_pred.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "        accuracy = 100. * correct / len(images)\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if batch_idx % 100  == 0:\n",
    "            print('TRAIN: LOSS-->{loss.val:.4f} ({loss.avg:.4f})\\t' 'ACC-->{acc.val:.3f}% ({acc.avg:.3f}%)'.format(loss=losses, acc=acc))\n",
    "            if use_tensorboard:\n",
    "                exp.add_scalar_value('tr_epoch_loss', losses.avg, step=epoch)\n",
    "                exp.add_scalar_value('tr_epoch_acc', acc.avg, step=epoch)\n",
    "                \n",
    "            print('TRAIN: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.3f}%)'.format(\n",
    "                epoch, batch_idx * len(images), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0],\n",
    "                correct, len(images),\n",
    "                accuracy))            \n",
    "    \n",
    "\n",
    "    return float('{loss.avg:.4f}'.format(loss=losses)), float('{acc.avg:.4f}'.format(acc=acc))\n",
    "\n",
    "def validate(val_loader, model, epoch):\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "        criterion.cuda()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, labels) in enumerate(val_loader):\n",
    "\n",
    "        if use_cuda:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            images, labels = Variable(images, volatile=True), Variable(labels)\n",
    "\n",
    "        # compute y_pred\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, labels)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, temp_var = accuracy2(y_pred.data, labels.data, topk=(1, 1))\n",
    "        losses.update(loss.data[0], images.size(0))\n",
    "        acc.update(prec1[0], images.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100== 0:\n",
    "            print('VAL:   LOSS--> {loss.val:.4f} ({loss.avg:.4f})\\t''ACC-->{acc.val:.3f} ({acc.avg:.3f})'.format(loss=losses, acc=acc))\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            if use_tensorboard:\n",
    "                exp.add_scalar_value('val_epoch_loss', losses.avg, step=epoch)\n",
    "                exp.add_scalar_value('val_epoch_acc', acc.avg, step=epoch)\n",
    "\n",
    "    print(' * Accuracy {acc.avg:.4f}'.format(acc=acc))\n",
    "    return float('{loss.avg:.6f}'.format(loss=losses)), float('{acc.avg:.6f}'.format(acc=acc))\n",
    "\n",
    "test_trans = valid_trans\n",
    "test_data_dir = 'd:/db/data/seedings/test/'\n",
    "\n",
    "def testImageLoader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "#     image = Image.open(image_name)\n",
    "    image = Image.open(image_name).convert('RGB')\n",
    "    image = test_trans(image)\n",
    "#     image = Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)  \n",
    "    if use_cuda:\n",
    "#         print (\"cuda\")\n",
    "        image.cuda()         \n",
    "    return image  \n",
    "\n",
    "def testModel(test_dir, local_model):    \n",
    "    if use_cuda:\n",
    "        local_model.cuda()\n",
    "    \n",
    "    local_model.eval()\n",
    "    \n",
    "    columns = ['file', 'species']\n",
    "    df_pred = pd.DataFrame(data=np.zeros((0, len(columns))), columns=columns)\n",
    "#     df_pred.species.astype(int)\n",
    "    for index, row in (sample_submission.iterrows()):\n",
    "#         for file in os.listdir(test_dir):            \n",
    "        currImage=os.path.join(test_dir, row['file'])\n",
    "        if os.path.isfile(currImage):\n",
    "            X_tensor_test=testImageLoader (currImage)            \n",
    "#             print (type(X_tensor_test))\n",
    "            if use_cuda:\n",
    "                X_tensor_test = Variable(X_tensor_test.cuda()) \n",
    "            else:\n",
    "                X_tensor_test = Variable(X_tensor_test)        \n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            predicted_val = (local_model(X_tensor_test)).data.max(1)[1] # get the index of the max log-probability\n",
    "#             predicted_val = predicted_val.data.max(1, keepdim=True)[1]\n",
    "            p_test = (predicted_val.cpu().numpy().item())\n",
    "            df_pred = df_pred.append({'file': row['file'], 'species': num_to_class[int(p_test)]}, ignore_index=True)             \n",
    "    \n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7b939262-bef9-4384-9e65-1c6f19b0e7af",
    "_uuid": "c89aec6e431baa5ad878aa07c30faef161dea697"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c75d0756-757e-4cdb-b3e3-43d0ae2110eb",
    "_uuid": "56b469e006382a0c93c7ce30b7976783257762b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: SimpleNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->2.4837 (2.4837)\tACC-->18.750% (18.750%)\n",
      "TRAIN: 0 [0/4038 (0%)]\tLoss: 2.483661, Accuracy: 3/16 (18.750%)\n",
      "TRAIN: LOSS-->1.9329 (2.2485)\tACC-->43.750% (23.577%)\n",
      "TRAIN: 0 [1600/4038 (40%)]\tLoss: 1.932917, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.7438 (2.1423)\tACC-->37.500% (25.902%)\n",
      "TRAIN: 0 [3200/4038 (79%)]\tLoss: 1.743805, Accuracy: 6/16 (37.500%)\n",
      "VAL:   LOSS--> 1.7574 (1.7574)\tACC-->31.250 (31.250)\n",
      " * Accuracy 36.5169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                               | 1/100 [01:02<1:43:25, 62.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.8231 (1.8231)\tACC-->31.250% (31.250%)\n",
      "TRAIN: 1 [0/4038 (0%)]\tLoss: 1.823076, Accuracy: 5/16 (31.250%)\n",
      "TRAIN: LOSS-->2.0315 (1.9430)\tACC-->37.500% (35.953%)\n",
      "TRAIN: 1 [1600/4038 (40%)]\tLoss: 2.031461, Accuracy: 6/16 (37.500%)\n",
      "TRAIN: LOSS-->1.8055 (1.8935)\tACC-->43.750% (36.785%)\n",
      "TRAIN: 1 [3200/4038 (79%)]\tLoss: 1.805523, Accuracy: 7/16 (43.750%)\n",
      "VAL:   LOSS--> 1.6274 (1.6274)\tACC-->50.000 (50.000)\n",
      " * Accuracy 50.5618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▌                                                                              | 2/100 [01:57<1:36:04, 58.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.3617 (1.3617)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 2 [0/4038 (0%)]\tLoss: 1.361687, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->1.6788 (1.7454)\tACC-->37.500% (41.584%)\n",
      "TRAIN: 2 [1600/4038 (40%)]\tLoss: 1.678803, Accuracy: 6/16 (37.500%)\n",
      "TRAIN: LOSS-->1.3372 (1.7247)\tACC-->56.250% (41.480%)\n",
      "TRAIN: 2 [3200/4038 (79%)]\tLoss: 1.337159, Accuracy: 9/16 (56.250%)\n",
      "VAL:   LOSS--> 1.5621 (1.5621)\tACC-->50.000 (50.000)\n",
      " * Accuracy 51.8258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                             | 3/100 [02:52<1:32:54, 57.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.9854 (1.9854)\tACC-->31.250% (31.250%)\n",
      "TRAIN: 3 [0/4038 (0%)]\tLoss: 1.985434, Accuracy: 5/16 (31.250%)\n",
      "TRAIN: LOSS-->1.5470 (1.6990)\tACC-->31.250% (42.512%)\n",
      "TRAIN: 3 [1600/4038 (40%)]\tLoss: 1.547006, Accuracy: 5/16 (31.250%)\n",
      "TRAIN: LOSS-->1.7760 (1.6625)\tACC-->37.500% (44.558%)\n",
      "TRAIN: 3 [3200/4038 (79%)]\tLoss: 1.775984, Accuracy: 6/16 (37.500%)\n",
      "VAL:   LOSS--> 1.0828 (1.0828)\tACC-->62.500 (62.500)\n",
      " * Accuracy 60.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▏                                                                            | 4/100 [03:47<1:30:48, 56.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.5896 (1.5896)\tACC-->31.250% (31.250%)\n",
      "TRAIN: 4 [0/4038 (0%)]\tLoss: 1.589611, Accuracy: 5/16 (31.250%)\n",
      "TRAIN: LOSS-->1.6358 (1.5844)\tACC-->50.000% (45.916%)\n",
      "TRAIN: 4 [1600/4038 (40%)]\tLoss: 1.635818, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->1.5291 (1.5687)\tACC-->43.750% (46.113%)\n",
      "TRAIN: 4 [3200/4038 (79%)]\tLoss: 1.529099, Accuracy: 7/16 (43.750%)\n",
      "VAL:   LOSS--> 1.3693 (1.3693)\tACC-->31.250 (31.250)\n",
      " * Accuracy 65.5899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████                                                                            | 5/100 [04:41<1:29:14, 56.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.5099 (1.5099)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 5 [0/4038 (0%)]\tLoss: 1.509910, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->1.8435 (1.4640)\tACC-->56.250% (50.248%)\n",
      "TRAIN: 5 [1600/4038 (40%)]\tLoss: 1.843495, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.5505 (1.4880)\tACC-->50.000% (49.845%)\n",
      "TRAIN: 5 [3200/4038 (79%)]\tLoss: 1.550495, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 0.7400 (0.7400)\tACC-->75.000 (75.000)\n",
      " * Accuracy 66.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                           | 6/100 [05:36<1:27:52, 56.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.9428 (1.9428)\tACC-->37.500% (37.500%)\n",
      "TRAIN: 6 [0/4038 (0%)]\tLoss: 1.942766, Accuracy: 6/16 (37.500%)\n",
      "TRAIN: LOSS-->1.2555 (1.4861)\tACC-->50.000% (50.495%)\n",
      "TRAIN: 6 [1600/4038 (40%)]\tLoss: 1.255460, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->1.6343 (1.4596)\tACC-->56.250% (51.835%)\n",
      "TRAIN: 6 [3200/4038 (79%)]\tLoss: 1.634311, Accuracy: 9/16 (56.250%)\n",
      "VAL:   LOSS--> 0.8689 (0.8689)\tACC-->81.250 (81.250)\n",
      " * Accuracy 64.4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▌                                                                          | 7/100 [06:31<1:26:39, 55.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.4945 (1.4945)\tACC-->43.750% (43.750%)\n",
      "TRAIN: 7 [0/4038 (0%)]\tLoss: 1.494483, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->0.9107 (1.3999)\tACC-->81.250% (54.208%)\n",
      "TRAIN: 7 [1600/4038 (40%)]\tLoss: 0.910716, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->1.5816 (1.4002)\tACC-->37.500% (53.856%)\n",
      "TRAIN: 7 [3200/4038 (79%)]\tLoss: 1.581565, Accuracy: 6/16 (37.500%)\n",
      "VAL:   LOSS--> 1.0850 (1.0850)\tACC-->62.500 (62.500)\n",
      " * Accuracy 68.2584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                         | 8/100 [07:26<1:25:31, 55.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.7082 (1.7082)\tACC-->43.750% (43.750%)\n",
      "TRAIN: 8 [0/4038 (0%)]\tLoss: 1.708192, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.3320 (1.3619)\tACC-->56.250% (55.012%)\n",
      "TRAIN: 8 [1600/4038 (40%)]\tLoss: 1.331987, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.3835 (1.3509)\tACC-->56.250% (54.198%)\n",
      "TRAIN: 8 [3200/4038 (79%)]\tLoss: 1.383517, Accuracy: 9/16 (56.250%)\n",
      "VAL:   LOSS--> 0.6203 (0.6203)\tACC-->81.250 (81.250)\n",
      " * Accuracy 66.4326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▏                                                                        | 9/100 [08:20<1:24:25, 55.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9882 (0.9882)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 9 [0/4038 (0%)]\tLoss: 0.988216, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->1.6712 (1.3049)\tACC-->31.250% (54.827%)\n",
      "TRAIN: 9 [1600/4038 (40%)]\tLoss: 1.671164, Accuracy: 5/16 (31.250%)\n",
      "TRAIN: LOSS-->1.6080 (1.3195)\tACC-->50.000% (54.602%)\n",
      "TRAIN: 9 [3200/4038 (79%)]\tLoss: 1.607960, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 1.0163 (1.0163)\tACC-->56.250 (56.250)\n",
      " * Accuracy 73.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▉                                                                       | 10/100 [09:15<1:23:22, 55.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.3352 (1.3352)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 10 [0/4038 (0%)]\tLoss: 1.335181, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.1133 (1.2971)\tACC-->56.250% (57.364%)\n",
      "TRAIN: 10 [1600/4038 (40%)]\tLoss: 1.113259, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.5133 (1.2624)\tACC-->56.250% (57.276%)\n",
      "TRAIN: 10 [3200/4038 (79%)]\tLoss: 1.513253, Accuracy: 9/16 (56.250%)\n",
      "VAL:   LOSS--> 0.7304 (0.7304)\tACC-->81.250 (81.250)\n",
      " * Accuracy 74.5787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▋                                                                      | 11/100 [10:10<1:22:20, 55.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.5264 (1.5264)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 11 [0/4038 (0%)]\tLoss: 1.526416, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.3263 (1.2519)\tACC-->37.500% (57.364%)\n",
      "TRAIN: 11 [1600/4038 (40%)]\tLoss: 1.326327, Accuracy: 6/16 (37.500%)\n",
      "TRAIN: LOSS-->1.6395 (1.2476)\tACC-->37.500% (58.271%)\n",
      "TRAIN: 11 [3200/4038 (79%)]\tLoss: 1.639492, Accuracy: 6/16 (37.500%)\n",
      "VAL:   LOSS--> 0.4765 (0.4765)\tACC-->81.250 (81.250)\n",
      " * Accuracy 76.9663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▍                                                                     | 12/100 [11:05<1:21:18, 55.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.5329 (1.5329)\tACC-->37.500% (37.500%)\n",
      "TRAIN: 12 [0/4038 (0%)]\tLoss: 1.532901, Accuracy: 6/16 (37.500%)\n",
      "TRAIN: LOSS-->1.2700 (1.2171)\tACC-->56.250% (59.035%)\n",
      "TRAIN: 12 [1600/4038 (40%)]\tLoss: 1.270005, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.5345 (1.2252)\tACC-->37.500% (58.613%)\n",
      "TRAIN: 12 [3200/4038 (79%)]\tLoss: 1.534454, Accuracy: 6/16 (37.500%)\n",
      "VAL:   LOSS--> 0.6462 (0.6462)\tACC-->68.750 (68.750)\n",
      " * Accuracy 74.1573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▎                                                                    | 13/100 [12:00<1:20:18, 55.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.2815 (1.2815)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 13 [0/4038 (0%)]\tLoss: 1.281488, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.6497 (1.1494)\tACC-->43.750% (61.200%)\n",
      "TRAIN: 13 [1600/4038 (40%)]\tLoss: 1.649678, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.1400 (1.2022)\tACC-->62.500% (58.800%)\n",
      "TRAIN: 13 [3200/4038 (79%)]\tLoss: 1.139971, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.4695 (0.4695)\tACC-->87.500 (87.500)\n",
      " * Accuracy 78.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████                                                                    | 14/100 [12:54<1:19:19, 55.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.6029 (1.6029)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 14 [0/4038 (0%)]\tLoss: 1.602925, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.7499 (1.1417)\tACC-->68.750% (60.458%)\n",
      "TRAIN: 14 [1600/4038 (40%)]\tLoss: 0.749876, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.4517 (1.1597)\tACC-->37.500% (60.012%)\n",
      "TRAIN: 14 [3200/4038 (79%)]\tLoss: 1.451696, Accuracy: 6/16 (37.500%)\n",
      "VAL:   LOSS--> 0.7964 (0.7964)\tACC-->68.750 (68.750)\n",
      " * Accuracy 72.8933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████▊                                                                   | 15/100 [13:49<1:18:19, 55.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.1325 (1.1325)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 15 [0/4038 (0%)]\tLoss: 1.132470, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.3620 (1.1780)\tACC-->56.250% (60.520%)\n",
      "TRAIN: 15 [1600/4038 (40%)]\tLoss: 1.361978, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.0235 (1.1438)\tACC-->62.500% (61.878%)\n",
      "TRAIN: 15 [3200/4038 (79%)]\tLoss: 1.023452, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.5436 (0.5436)\tACC-->68.750 (68.750)\n",
      " * Accuracy 78.6517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▋                                                                  | 16/100 [14:44<1:17:21, 55.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.1892 (1.1892)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 16 [0/4038 (0%)]\tLoss: 1.189198, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.6389 (1.0955)\tACC-->87.500% (63.985%)\n",
      "TRAIN: 16 [1600/4038 (40%)]\tLoss: 0.638870, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->1.2229 (1.0916)\tACC-->62.500% (63.775%)\n",
      "TRAIN: 16 [3200/4038 (79%)]\tLoss: 1.222909, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.6611 (0.6611)\tACC-->68.750 (68.750)\n",
      " * Accuracy 78.0899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▍                                                                 | 17/100 [15:38<1:16:23, 55.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0434 (1.0434)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 17 [0/4038 (0%)]\tLoss: 1.043371, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.4953 (1.1415)\tACC-->50.000% (61.757%)\n",
      "TRAIN: 17 [1600/4038 (40%)]\tLoss: 1.495280, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->0.6477 (1.1072)\tACC-->81.250% (62.749%)\n",
      "TRAIN: 17 [3200/4038 (79%)]\tLoss: 0.647738, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.8071 (0.8071)\tACC-->56.250 (56.250)\n",
      " * Accuracy 79.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▏                                                                | 18/100 [16:33<1:15:25, 55.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.1882 (1.1882)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 18 [0/4038 (0%)]\tLoss: 1.188209, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.7973 (1.0378)\tACC-->68.750% (64.542%)\n",
      "TRAIN: 18 [1600/4038 (40%)]\tLoss: 0.797301, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.8014 (1.0446)\tACC-->68.750% (64.335%)\n",
      "TRAIN: 18 [3200/4038 (79%)]\tLoss: 0.801417, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.4019 (0.4019)\tACC-->81.250 (81.250)\n",
      " * Accuracy 77.3876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████                                                                | 19/100 [17:28<1:14:28, 55.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0353 (1.0353)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 19 [0/4038 (0%)]\tLoss: 1.035253, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.5897 (1.0658)\tACC-->68.750% (63.923%)\n",
      "TRAIN: 19 [1600/4038 (40%)]\tLoss: 1.589749, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.0252 (1.0634)\tACC-->50.000% (63.619%)\n",
      "TRAIN: 19 [3200/4038 (79%)]\tLoss: 1.025164, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 0.7404 (0.7404)\tACC-->87.500 (87.500)\n",
      " * Accuracy 77.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▊                                                               | 20/100 [18:22<1:13:31, 55.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.4090 (1.4090)\tACC-->43.750% (43.750%)\n",
      "TRAIN: 20 [0/4038 (0%)]\tLoss: 1.409002, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.1172 (1.0623)\tACC-->75.000% (64.480%)\n",
      "TRAIN: 20 [1600/4038 (40%)]\tLoss: 1.117217, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->1.0932 (1.0418)\tACC-->68.750% (64.894%)\n",
      "TRAIN: 20 [3200/4038 (79%)]\tLoss: 1.093195, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.6476 (0.6476)\tACC-->81.250 (81.250)\n",
      " * Accuracy 82.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████▌                                                              | 21/100 [19:17<1:12:35, 55.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.0406 (1.0406)\tACC-->56.250% (56.250%)\n",
      "TRAIN: 21 [0/4038 (0%)]\tLoss: 1.040584, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->1.1296 (1.0362)\tACC-->37.500% (63.119%)\n",
      "TRAIN: 21 [1600/4038 (40%)]\tLoss: 1.129632, Accuracy: 6/16 (37.500%)\n",
      "TRAIN: LOSS-->0.9627 (1.0031)\tACC-->81.250% (65.361%)\n",
      "TRAIN: 21 [3200/4038 (79%)]\tLoss: 0.962684, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.4526 (0.4526)\tACC-->87.500 (87.500)\n",
      " * Accuracy 80.7584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▍                                                             | 22/100 [20:12<1:11:38, 55.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.2664 (1.2664)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 22 [0/4038 (0%)]\tLoss: 1.266386, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.1411 (0.9652)\tACC-->50.000% (66.399%)\n",
      "TRAIN: 22 [1600/4038 (40%)]\tLoss: 1.141072, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->1.5634 (0.9633)\tACC-->62.500% (66.822%)\n",
      "TRAIN: 22 [3200/4038 (79%)]\tLoss: 1.563418, Accuracy: 10/16 (62.500%)\n",
      "VAL:   LOSS--> 0.5141 (0.5141)\tACC-->81.250 (81.250)\n",
      " * Accuracy 82.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▏                                                            | 23/100 [21:07<1:10:42, 55.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.5912 (0.5912)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 23 [0/4038 (0%)]\tLoss: 0.591242, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.7277 (0.9746)\tACC-->81.250% (66.955%)\n",
      "TRAIN: 23 [1600/4038 (40%)]\tLoss: 0.727695, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->1.1198 (1.0105)\tACC-->50.000% (65.516%)\n",
      "TRAIN: 23 [3200/4038 (79%)]\tLoss: 1.119835, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 0.5036 (0.5036)\tACC-->81.250 (81.250)\n",
      " * Accuracy 83.9888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████████████▉                                                            | 24/100 [22:01<1:09:45, 55.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7063 (0.7063)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 24 [0/4038 (0%)]\tLoss: 0.706280, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.7490 (0.9724)\tACC-->68.750% (66.522%)\n",
      "TRAIN: 24 [1600/4038 (40%)]\tLoss: 0.749031, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.6018 (0.9755)\tACC-->81.250% (66.760%)\n",
      "TRAIN: 24 [3200/4038 (79%)]\tLoss: 0.601821, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.2322 (0.2322)\tACC-->87.500 (87.500)\n",
      " * Accuracy 82.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████▊                                                           | 25/100 [22:56<1:08:49, 55.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->1.4414 (1.4414)\tACC-->50.000% (50.000%)\n",
      "TRAIN: 25 [0/4038 (0%)]\tLoss: 1.441384, Accuracy: 8/16 (50.000%)\n",
      "TRAIN: LOSS-->0.7289 (0.9874)\tACC-->81.250% (65.903%)\n",
      "TRAIN: 25 [1600/4038 (40%)]\tLoss: 0.728937, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->1.4820 (0.9956)\tACC-->50.000% (65.485%)\n",
      "TRAIN: 25 [3200/4038 (79%)]\tLoss: 1.482006, Accuracy: 8/16 (50.000%)\n",
      "VAL:   LOSS--> 0.5724 (0.5724)\tACC-->81.250 (81.250)\n",
      " * Accuracy 80.8989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▌                                                          | 26/100 [23:51<1:07:53, 55.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6730 (0.6730)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 26 [0/4038 (0%)]\tLoss: 0.672989, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.6712 (0.9774)\tACC-->75.000% (67.203%)\n",
      "TRAIN: 26 [1600/4038 (40%)]\tLoss: 0.671151, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.7491 (0.9542)\tACC-->68.750% (67.164%)\n",
      "TRAIN: 26 [3200/4038 (79%)]\tLoss: 0.749055, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.6858 (0.6858)\tACC-->75.000 (75.000)\n",
      " * Accuracy 78.0899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▎                                                         | 27/100 [24:46<1:06:57, 55.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.6777 (0.6777)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 27 [0/4038 (0%)]\tLoss: 0.677654, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.8277 (0.9338)\tACC-->75.000% (68.564%)\n",
      "TRAIN: 27 [1600/4038 (40%)]\tLoss: 0.827676, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.9006 (0.9069)\tACC-->68.750% (69.123%)\n",
      "TRAIN: 27 [3200/4038 (79%)]\tLoss: 0.900597, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.6712 (0.6712)\tACC-->81.250 (81.250)\n",
      " * Accuracy 82.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████                                                         | 28/100 [25:40<1:06:01, 55.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9694 (0.9694)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 28 [0/4038 (0%)]\tLoss: 0.969354, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->1.1106 (0.9617)\tACC-->56.250% (67.450%)\n",
      "TRAIN: 28 [1600/4038 (40%)]\tLoss: 1.110637, Accuracy: 9/16 (56.250%)\n",
      "TRAIN: LOSS-->0.7632 (0.9372)\tACC-->75.000% (68.408%)\n",
      "TRAIN: 28 [3200/4038 (79%)]\tLoss: 0.763239, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.7387 (0.7387)\tACC-->81.250 (81.250)\n",
      " * Accuracy 77.8090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██████████████████████▉                                                        | 29/100 [26:35<1:05:06, 55.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.4926 (0.4926)\tACC-->87.500% (87.500%)\n",
      "TRAIN: 29 [0/4038 (0%)]\tLoss: 0.492555, Accuracy: 14/16 (87.500%)\n",
      "TRAIN: LOSS-->1.1918 (0.9111)\tACC-->62.500% (70.173%)\n",
      "TRAIN: 29 [1600/4038 (40%)]\tLoss: 1.191823, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.5649 (0.9165)\tACC-->87.500% (69.341%)\n",
      "TRAIN: 29 [3200/4038 (79%)]\tLoss: 0.564882, Accuracy: 14/16 (87.500%)\n",
      "VAL:   LOSS--> 0.3620 (0.3620)\tACC-->87.500 (87.500)\n",
      " * Accuracy 82.8652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▋                                                       | 30/100 [27:30<1:04:10, 55.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9498 (0.9498)\tACC-->81.250% (81.250%)\n",
      "TRAIN: 30 [0/4038 (0%)]\tLoss: 0.949801, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->1.2345 (0.9367)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 30 [1600/4038 (40%)]\tLoss: 1.234529, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.5618 (0.9353)\tACC-->81.250% (68.408%)\n",
      "TRAIN: 30 [3200/4038 (79%)]\tLoss: 0.561793, Accuracy: 13/16 (81.250%)\n",
      "VAL:   LOSS--> 0.2791 (0.2791)\tACC-->87.500 (87.500)\n",
      " * Accuracy 85.3933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████▍                                                      | 31/100 [28:25<1:03:15, 55.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7701 (0.7701)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 31 [0/4038 (0%)]\tLoss: 0.770115, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->1.3423 (0.8850)\tACC-->43.750% (70.050%)\n",
      "TRAIN: 31 [1600/4038 (40%)]\tLoss: 1.342266, Accuracy: 7/16 (43.750%)\n",
      "TRAIN: LOSS-->1.0229 (0.9274)\tACC-->75.000% (68.626%)\n",
      "TRAIN: 31 [3200/4038 (79%)]\tLoss: 1.022948, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.2445 (0.2445)\tACC-->93.750 (93.750)\n",
      " * Accuracy 81.7416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▎                                                     | 32/100 [29:19<1:02:19, 54.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.7707 (0.7707)\tACC-->75.000% (75.000%)\n",
      "TRAIN: 32 [0/4038 (0%)]\tLoss: 0.770723, Accuracy: 12/16 (75.000%)\n",
      "TRAIN: LOSS-->0.6058 (0.9226)\tACC-->81.250% (68.317%)\n",
      "TRAIN: 32 [1600/4038 (40%)]\tLoss: 0.605760, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->0.7948 (0.8953)\tACC-->75.000% (69.403%)\n",
      "TRAIN: 32 [3200/4038 (79%)]\tLoss: 0.794781, Accuracy: 12/16 (75.000%)\n",
      "VAL:   LOSS--> 0.4138 (0.4138)\tACC-->81.250 (81.250)\n",
      " * Accuracy 82.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████                                                     | 33/100 [30:14<1:01:24, 54.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9297 (0.9297)\tACC-->62.500% (62.500%)\n",
      "TRAIN: 33 [0/4038 (0%)]\tLoss: 0.929695, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->1.0023 (0.8966)\tACC-->62.500% (69.059%)\n",
      "TRAIN: 33 [1600/4038 (40%)]\tLoss: 1.002339, Accuracy: 10/16 (62.500%)\n",
      "TRAIN: LOSS-->0.7756 (0.8810)\tACC-->68.750% (69.403%)\n",
      "TRAIN: 33 [3200/4038 (79%)]\tLoss: 0.775562, Accuracy: 11/16 (68.750%)\n",
      "VAL:   LOSS--> 0.3695 (0.3695)\tACC-->93.750 (93.750)\n",
      " * Accuracy 84.9719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████████████▊                                                    | 34/100 [31:10<1:00:30, 55.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.8222 (0.8222)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 34 [0/4038 (0%)]\tLoss: 0.822200, Accuracy: 11/16 (68.750%)\n",
      "TRAIN: LOSS-->0.5874 (0.8827)\tACC-->81.250% (70.111%)\n",
      "TRAIN: 34 [1600/4038 (40%)]\tLoss: 0.587422, Accuracy: 13/16 (81.250%)\n",
      "TRAIN: LOSS-->1.1738 (0.8713)\tACC-->56.250% (70.771%)\n",
      "TRAIN: 34 [3200/4038 (79%)]\tLoss: 1.173847, Accuracy: 9/16 (56.250%)\n",
      "VAL:   LOSS--> 0.4085 (0.4085)\tACC-->81.250 (81.250)\n",
      " * Accuracy 87.6404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▎                                                    | 35/100 [32:05<59:36, 55.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: LOSS-->0.9196 (0.9196)\tACC-->68.750% (68.750%)\n",
      "TRAIN: 35 [0/4038 (0%)]\tLoss: 0.919577, Accuracy: 11/16 (68.750%)\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "sample_submission.columns = ['file', 'species']\n",
    "# sample_submission['category_id'] = 0\n",
    "sample_submission.head(3)\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    print (\"MODEL: {}\".format( str(type(model).__name__)))\n",
    "    for epoch in tqdm(range(0, 100)):        \n",
    "        train(t_loader, model, epoch, optimizer)\n",
    "        val_loss, val_accuracy= validate(v_loader, model, epoch)\n",
    "        if float(val_accuracy) > float(90.0):            \n",
    "            print (\"EARLY STOP\")\n",
    "            df_pred=testModel(test_data_dir,model)\n",
    "            df_pred.to_csv(str(type(model).__name__) + '_' + str(val_accuracy) + '_' + \n",
    "                           str(epoch) + \"_sub.csv\", columns=('file', 'species'), index=None)         \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example submission on the Kaggle seedlings DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), str(type(model).__name__) + '_' + str(val_accuracy) + '_.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, participants will be asked to provide the following classification rates:\n",
    "\n",
    "-- TP (True Positive, which is the number of OP people correctly identified),\n",
    "\n",
    "-- FP (False Positive, which is the number of CT people incorrectly identified),\n",
    "\n",
    "-- TN (True Negative, which is the number of CT people correctly identified),\n",
    "\n",
    "-- FN (False Negative, which is the number of OP people incorrectly identified),\n",
    "\n",
    "-- Sn (True positive rate or sensitivity) as Sn = TP/(TP + FN),\n",
    "\n",
    "-- Sp (Specificity or True Negative Rate) as Sp = TN/(FP + TN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
